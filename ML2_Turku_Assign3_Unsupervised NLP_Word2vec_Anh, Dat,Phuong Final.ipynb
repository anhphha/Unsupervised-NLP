{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of abstracts in folder awards_2002: 9923\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import os\n",
    "import re\n",
    "\n",
    "def get_fnames():\n",
    "    \"\"\"Read all text files in a folder.\n",
    "    \"\"\"\n",
    "    fnames = []\n",
    "    for root,_,files in os.walk(\"./abstracts/awards_2002\"):\n",
    "        for fname in files:\n",
    "            if fname[-4:] == \".txt\":\n",
    "                fnames.append(os.path.join(root, fname))\n",
    "    return fnames\n",
    "\n",
    "print(\"Number of abstracts in folder awards_2002: {}\".format(len(get_fnames())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_list = get_fnames()\n",
    "\n",
    "def read_file(fname):\n",
    "    with open(fname, 'r',encoding=\"ISO-8859-1\") as f:\n",
    "        # skip all lines until abstract\n",
    "        for line in f:\n",
    "            if \"Abstract    :\" in line:\n",
    "                break\n",
    "\n",
    "        # get abstract as a single string\n",
    "        abstract = ' '.join([line[:-1].strip() for line in f])\n",
    "        abstract = re.sub(' +', ' ', abstract)  # remove double spaces\n",
    "        return abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = []\n",
    "\n",
    "for i in name_list:\n",
    "    documents.append(read_file(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Fast and simple tokenization\n",
    "new_vectorizer = TfidfVectorizer(stop_words = 'english', lowercase= True, ngram_range = (1,3) ,min_df=5, use_idf=True, sublinear_tf=True, max_df=1.0)\n",
    "word_tokenizer = new_vectorizer.build_tokenizer()\n",
    "tokenized_text = [word_tokenizer(doc) for doc in documents]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This',\n",
       " 'Small',\n",
       " 'Business',\n",
       " 'Innovation',\n",
       " 'Research',\n",
       " 'SBIR',\n",
       " 'Phase',\n",
       " 'II',\n",
       " 'Project',\n",
       " 'proposes',\n",
       " 'to',\n",
       " 'develop',\n",
       " 'the',\n",
       " 'database',\n",
       " 'and',\n",
       " 'associated',\n",
       " 'software',\n",
       " 'to',\n",
       " 'enable',\n",
       " 'analysis',\n",
       " 'of',\n",
       " 'protein',\n",
       " 'trafficking',\n",
       " 'and',\n",
       " 'localization',\n",
       " 'The',\n",
       " 'system',\n",
       " 'will',\n",
       " 'be',\n",
       " 'designed',\n",
       " 'to',\n",
       " 'enable',\n",
       " 'drug',\n",
       " 'discovery',\n",
       " 'researchers',\n",
       " 'to',\n",
       " 'identify',\n",
       " 'elucidate',\n",
       " 'eliminate',\n",
       " 'and',\n",
       " 'design',\n",
       " 'leads',\n",
       " 'and',\n",
       " 'targets',\n",
       " 'while',\n",
       " 'facilitating',\n",
       " 'the',\n",
       " 'general',\n",
       " 'training',\n",
       " 'of',\n",
       " 'researchers',\n",
       " 'During',\n",
       " 'the',\n",
       " 'Phase',\n",
       " 'work',\n",
       " 'proteins',\n",
       " 'involved',\n",
       " 'in',\n",
       " 'trafficking',\n",
       " 'and',\n",
       " 'diseases',\n",
       " 'related',\n",
       " 'to',\n",
       " 'mislocalization',\n",
       " 'were',\n",
       " 'identified',\n",
       " 'and',\n",
       " 'relational',\n",
       " 'database',\n",
       " 'to',\n",
       " 'house',\n",
       " 'information',\n",
       " 'on',\n",
       " 'protein',\n",
       " 'trafficking',\n",
       " 'was',\n",
       " 'constructed',\n",
       " 'Curation',\n",
       " 'interface',\n",
       " 'applications',\n",
       " 'were',\n",
       " 'created',\n",
       " 'to',\n",
       " 'allow',\n",
       " 'remote',\n",
       " 'data',\n",
       " 'entry',\n",
       " 'and',\n",
       " 'graphical',\n",
       " 'user',\n",
       " 'interfaces',\n",
       " 'designed',\n",
       " 'to',\n",
       " 'maximize',\n",
       " 'the',\n",
       " 'utility',\n",
       " 'of',\n",
       " 'the',\n",
       " 'information',\n",
       " 'The',\n",
       " 'objective',\n",
       " 'of',\n",
       " 'this',\n",
       " 'Phase',\n",
       " 'II',\n",
       " 'Project',\n",
       " 'is',\n",
       " 'to',\n",
       " 'exhaustively',\n",
       " 'populate',\n",
       " 'the',\n",
       " 'database',\n",
       " 'from',\n",
       " 'the',\n",
       " 'primary',\n",
       " 'journal',\n",
       " 'literature',\n",
       " 'Selection',\n",
       " 'of',\n",
       " 'proteins',\n",
       " 'involved',\n",
       " 'in',\n",
       " 'protein',\n",
       " 'trafficking',\n",
       " 'will',\n",
       " 'be',\n",
       " 'guided',\n",
       " 'by',\n",
       " 'relevant',\n",
       " 'human',\n",
       " 'diseases',\n",
       " 'and',\n",
       " 'corresponding',\n",
       " 'drug',\n",
       " 'discovery',\n",
       " 'efforts',\n",
       " 'The',\n",
       " 'commercial',\n",
       " 'application',\n",
       " 'of',\n",
       " 'this',\n",
       " 'project',\n",
       " 'is',\n",
       " 'in',\n",
       " 'the',\n",
       " 'area',\n",
       " 'of',\n",
       " 'biological',\n",
       " 'informatics',\n",
       " 'The',\n",
       " 'potential',\n",
       " 'users',\n",
       " 'of',\n",
       " 'the',\n",
       " 'biological',\n",
       " 'database',\n",
       " 'to',\n",
       " 'be',\n",
       " 'developed',\n",
       " 'in',\n",
       " 'this',\n",
       " 'project',\n",
       " 'would',\n",
       " 'include',\n",
       " 'pharmaceutical',\n",
       " 'and',\n",
       " 'drug',\n",
       " 'discovery',\n",
       " 'companies']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-26 21:45:03,167 : INFO : collecting all words and their counts\n",
      "2021-02-26 21:45:03,168 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2021-02-26 21:45:03,905 : INFO : collected 63538 word types from a corpus of 2656274 raw words and 9923 sentences\n",
      "2021-02-26 21:45:03,906 : INFO : Loading a fresh vocabulary\n",
      "2021-02-26 21:45:04,022 : INFO : effective_min_count=5 retains 20752 unique words (32% of original 63538, drops 42786)\n",
      "2021-02-26 21:45:04,023 : INFO : effective_min_count=5 leaves 2585188 word corpus (97% of original 2656274, drops 71086)\n",
      "2021-02-26 21:45:04,152 : INFO : deleting the raw counts dictionary of 63538 items\n",
      "2021-02-26 21:45:04,154 : INFO : sample=0.001 downsamples 26 most-common words\n",
      "2021-02-26 21:45:04,155 : INFO : downsampling leaves estimated 2005620 word corpus (77.6% of prior 2585188)\n",
      "2021-02-26 21:45:04,223 : INFO : estimated required memory for 20752 words and 100 dimensions: 26977600 bytes\n",
      "2021-02-26 21:45:04,224 : INFO : resetting layer weights\n",
      "2021-02-26 21:45:11,088 : INFO : training model with 4 workers on 20752 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=5\n",
      "2021-02-26 21:45:12,121 : INFO : EPOCH 1 - PROGRESS: at 18.65% examples, 353647 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 21:45:13,138 : INFO : EPOCH 1 - PROGRESS: at 36.28% examples, 352188 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 21:45:14,145 : INFO : EPOCH 1 - PROGRESS: at 52.62% examples, 345357 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 21:45:15,156 : INFO : EPOCH 1 - PROGRESS: at 70.68% examples, 345542 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 21:45:16,172 : INFO : EPOCH 1 - PROGRESS: at 86.79% examples, 342321 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 21:45:16,912 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-02-26 21:45:16,920 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-02-26 21:45:16,929 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-02-26 21:45:16,958 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-02-26 21:45:16,959 : INFO : EPOCH - 1 : training on 2656274 raw words (2006689 effective words) took 5.9s, 341953 effective words/s\n",
      "2021-02-26 21:45:17,985 : INFO : EPOCH 2 - PROGRESS: at 13.71% examples, 268927 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 21:45:18,990 : INFO : EPOCH 2 - PROGRESS: at 29.48% examples, 289724 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 21:45:20,000 : INFO : EPOCH 2 - PROGRESS: at 41.87% examples, 278742 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 21:45:21,007 : INFO : EPOCH 2 - PROGRESS: at 58.02% examples, 286529 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 21:45:22,014 : INFO : EPOCH 2 - PROGRESS: at 74.59% examples, 294110 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 21:45:23,017 : INFO : EPOCH 2 - PROGRESS: at 88.51% examples, 293377 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 21:45:23,694 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-02-26 21:45:23,717 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-02-26 21:45:23,725 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-02-26 21:45:23,745 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-02-26 21:45:23,746 : INFO : EPOCH - 2 : training on 2656274 raw words (2006413 effective words) took 6.8s, 295817 effective words/s\n",
      "2021-02-26 21:45:24,773 : INFO : EPOCH 3 - PROGRESS: at 14.12% examples, 275538 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 21:45:25,779 : INFO : EPOCH 3 - PROGRESS: at 23.78% examples, 230651 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 21:45:26,780 : INFO : EPOCH 3 - PROGRESS: at 39.77% examples, 262145 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 21:45:27,790 : INFO : EPOCH 3 - PROGRESS: at 56.02% examples, 277439 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 21:45:28,818 : INFO : EPOCH 3 - PROGRESS: at 72.95% examples, 285634 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 21:45:29,849 : INFO : EPOCH 3 - PROGRESS: at 88.51% examples, 290970 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 21:45:30,563 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-02-26 21:45:30,574 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-02-26 21:45:30,579 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-02-26 21:45:30,600 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-02-26 21:45:30,601 : INFO : EPOCH - 3 : training on 2656274 raw words (2004774 effective words) took 6.9s, 292597 effective words/s\n",
      "2021-02-26 21:45:31,671 : INFO : EPOCH 4 - PROGRESS: at 15.33% examples, 286098 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 21:45:32,671 : INFO : EPOCH 4 - PROGRESS: at 30.43% examples, 294511 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 21:45:33,681 : INFO : EPOCH 4 - PROGRESS: at 45.08% examples, 296976 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 21:45:34,689 : INFO : EPOCH 4 - PROGRESS: at 62.01% examples, 301821 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 21:45:35,715 : INFO : EPOCH 4 - PROGRESS: at 77.35% examples, 303701 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 21:45:36,728 : INFO : EPOCH 4 - PROGRESS: at 93.23% examples, 305483 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 21:45:37,112 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-02-26 21:45:37,113 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-02-26 21:45:37,124 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-02-26 21:45:37,172 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-02-26 21:45:37,174 : INFO : EPOCH - 4 : training on 2656274 raw words (2004878 effective words) took 6.6s, 305244 effective words/s\n",
      "2021-02-26 21:45:38,210 : INFO : EPOCH 5 - PROGRESS: at 15.33% examples, 295502 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 21:45:39,272 : INFO : EPOCH 5 - PROGRESS: at 31.49% examples, 301646 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 21:45:40,339 : INFO : EPOCH 5 - PROGRESS: at 47.34% examples, 303120 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 21:45:41,383 : INFO : EPOCH 5 - PROGRESS: at 63.08% examples, 298597 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 21:45:42,390 : INFO : EPOCH 5 - PROGRESS: at 76.19% examples, 292146 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 21:45:43,431 : INFO : EPOCH 5 - PROGRESS: at 90.99% examples, 292223 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 21:45:44,006 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-02-26 21:45:44,024 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-02-26 21:45:44,030 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-02-26 21:45:44,065 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-02-26 21:45:44,066 : INFO : EPOCH - 5 : training on 2656274 raw words (2006161 effective words) took 6.9s, 291208 effective words/s\n",
      "2021-02-26 21:45:44,067 : INFO : training on a 13281370 raw words (10028915 effective words) took 33.0s, 304099 effective words/s\n"
     ]
    }
   ],
   "source": [
    "### Train word vectors\n",
    "\n",
    "import gensim # Make sure you also have cython installed to accelerate computation!\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "\n",
    "# Train word2vec model\n",
    "vectors = gensim.models.Word2Vec(tokenized_text, size=100, min_count=5, sg=1, workers=4) # change tokenized_text to tfidf.matrix!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_word = [list(vectors.wv.vocab.keys())[(i+1)*1000] for i in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['greatly', 'every', 'includes', 'transcription', 'largest']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-26 13:33:02,414 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar to: greatly\n",
      "[('significantly', 0.8013008236885071), ('substantially', 0.7442965507507324), ('dramatically', 0.7396800518035889), ('vastly', 0.667165994644165), ('enlarge', 0.6540445685386658), ('MPICH', 0.6524852514266968), ('streamline', 0.6513089537620544), ('Successful', 0.6315666437149048), ('capability', 0.6274981498718262), ('sharpen', 0.6218451261520386)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Inspect words with vectors most similar to a given word\n",
    "print(\"Most similar to:\", 'greatly')\n",
    "print(vectors.wv.most_similar('greatly'))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar to: every\n",
      "[('each', 0.6906091570854187), ('Every', 0.6714961528778076), ('almost', 0.6605528593063354), ('essentially', 0.6477319002151489), ('normally', 0.6423296332359314), ('judiciously', 0.6373945474624634), ('roughly', 0.6333438158035278), ('nearly', 0.6281598806381226), ('again', 0.6260768175125122), ('morning', 0.6238182783126831)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Inspect words with vectors most similar to a given word\n",
    "print(\"Most similar to:\", 'every')\n",
    "print(vectors.wv.most_similar('every'))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar to: includes\n",
      "[('involves', 0.7543442249298096), ('consists', 0.7009209990501404), ('comprises', 0.6838739514350891), ('encompasses', 0.6799794435501099), ('supports', 0.6580832004547119), ('emphasizes', 0.6541271805763245), ('involve', 0.6530083417892456), ('include', 0.6529262065887451), ('integrates', 0.6281484961509705), ('introduces', 0.6225360631942749)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Inspect words with vectors most similar to a given word\n",
    "print(\"Most similar to:\", 'includes')\n",
    "print(vectors.wv.most_similar('includes'))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar to: transcription\n",
      "[('chromatin', 0.8633143305778503), ('silencing', 0.8584595918655396), ('mRNA', 0.8561317920684814), ('meiotic', 0.8526526689529419), ('transcriptional', 0.8488618731498718), ('repressor', 0.8470075130462646), ('homologous', 0.8436334729194641), ('replication', 0.8433512449264526), ('mRNAs', 0.8415851593017578), ('virulence', 0.8390907645225525)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Inspect words with vectors most similar to a given word\n",
    "print(\"Most similar to:\", 'transcription')\n",
    "print(vectors.wv.most_similar('transcription'))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar to: largest\n",
      "[('oldest', 0.739079475402832), ('populous', 0.7280933856964111), ('southeastern', 0.7225464582443237), ('towns', 0.7119206190109253), ('rest', 0.7053264379501343), ('richest', 0.6938225626945496), ('province', 0.6938113570213318), ('northeastern', 0.6901578307151794), ('deepest', 0.6891354322433472), ('endemic', 0.6792290210723877)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Inspect words with vectors most similar to a given word\n",
    "print(\"Most similar to:\", 'largest')\n",
    "print(vectors.wv.most_similar('largest'))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-26 13:33:28,249 : WARNING : consider setting layer size to a multiple of 4 for greater performance\n",
      "2021-02-26 13:33:28,251 : INFO : collecting all words and their counts\n",
      "2021-02-26 13:33:28,252 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2021-02-26 13:33:28,806 : INFO : collected 63538 word types from a corpus of 2656274 raw words and 9923 sentences\n",
      "2021-02-26 13:33:28,808 : INFO : Loading a fresh vocabulary\n",
      "2021-02-26 13:33:29,051 : INFO : effective_min_count=1 retains 63538 unique words (100% of original 63538, drops 0)\n",
      "2021-02-26 13:33:29,053 : INFO : effective_min_count=1 leaves 2656274 word corpus (100% of original 2656274, drops 0)\n",
      "2021-02-26 13:33:29,346 : INFO : deleting the raw counts dictionary of 63538 items\n",
      "2021-02-26 13:33:29,348 : INFO : sample=0.001 downsamples 25 most-common words\n",
      "2021-02-26 13:33:29,350 : INFO : downsampling leaves estimated 2081427 word corpus (78.4% of prior 2656274)\n",
      "2021-02-26 13:33:29,524 : INFO : estimated required memory for 63538 words and 10 dimensions: 36852040 bytes\n",
      "2021-02-26 13:33:29,525 : INFO : resetting layer weights\n",
      "2021-02-26 13:33:46,624 : INFO : training model with 4 workers on 63538 vocabulary and 10 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2021-02-26 13:33:47,631 : INFO : EPOCH 1 - PROGRESS: at 84.85% examples, 1753499 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 13:33:47,808 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-02-26 13:33:47,809 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-02-26 13:33:47,812 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-02-26 13:33:47,817 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-02-26 13:33:47,818 : INFO : EPOCH - 1 : training on 2656274 raw words (2081355 effective words) took 1.2s, 1750148 effective words/s\n",
      "2021-02-26 13:33:48,821 : INFO : EPOCH 2 - PROGRESS: at 85.16% examples, 1763794 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 13:33:48,994 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-02-26 13:33:48,995 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-02-26 13:33:48,999 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-02-26 13:33:49,003 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-02-26 13:33:49,004 : INFO : EPOCH - 2 : training on 2656274 raw words (2080906 effective words) took 1.2s, 1758384 effective words/s\n",
      "2021-02-26 13:33:50,007 : INFO : EPOCH 3 - PROGRESS: at 85.46% examples, 1771985 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 13:33:50,176 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-02-26 13:33:50,177 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-02-26 13:33:50,180 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-02-26 13:33:50,184 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-02-26 13:33:50,185 : INFO : EPOCH - 3 : training on 2656274 raw words (2080807 effective words) took 1.2s, 1765807 effective words/s\n",
      "2021-02-26 13:33:51,189 : INFO : EPOCH 4 - PROGRESS: at 85.46% examples, 1770808 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 13:33:51,360 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-02-26 13:33:51,361 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-02-26 13:33:51,365 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-02-26 13:33:51,369 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-02-26 13:33:51,370 : INFO : EPOCH - 4 : training on 2656274 raw words (2081643 effective words) took 1.2s, 1761448 effective words/s\n",
      "2021-02-26 13:33:52,374 : INFO : EPOCH 5 - PROGRESS: at 80.05% examples, 1661558 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 13:33:52,686 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-02-26 13:33:52,687 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-02-26 13:33:52,692 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-02-26 13:33:52,697 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-02-26 13:33:52,698 : INFO : EPOCH - 5 : training on 2656274 raw words (2081025 effective words) took 1.3s, 1569930 effective words/s\n",
      "2021-02-26 13:33:52,699 : INFO : training on a 13281370 raw words (10405736 effective words) took 6.1s, 1713386 effective words/s\n"
     ]
    }
   ],
   "source": [
    "vectors2 = gensim.models.Word2Vec(tokenized_text, size=10, min_count=1, sg=0, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_word2 = [list(vectors2.wv.vocab.keys())[(i+1)*1000] for i in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['half', 'whether', 'neuroscience', 'Lonza', 'tightly']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed_word2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-26 13:35:45,115 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar to: half\n",
      "[('thousand', 0.9656727313995361), ('80', 0.9651178121566772), ('percent', 0.9607995748519897), ('70', 0.9601696729660034), ('torn', 0.9574507474899292), ('parallelepipeds', 0.953171968460083), ('roughly', 0.9500912427902222), ('million', 0.9493248462677002), ('catecholamines', 0.9489266872406006), ('Dickenson', 0.9426918029785156)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Inspect words with vectors most similar to a given word\n",
    "print(\"Most similar to:\", 'half')\n",
    "print(vectors2.wv.most_similar('half'))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar to: whether\n",
      "[('what', 0.9122190475463867), ('macromodels', 0.9094517230987549), ('why', 0.9062631130218506), ('fissions', 0.8964521288871765), ('how', 0.8916631937026978), ('farmer', 0.8860977292060852), ('SWING', 0.8760378956794739), ('Proximate', 0.870087206363678), ('if', 0.8693884611129761), ('manhood', 0.857232391834259)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Inspect words with vectors most similar to a given word\n",
    "print(\"Most similar to:\", 'whether')\n",
    "print(vectors2.wv.most_similar('whether'))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar to: neuroscience\n",
      "[('populace', 0.9711309671401978), ('LCLUC', 0.9577138423919678), ('focusing', 0.9521087408065796), ('0231010', 0.9496864676475525), ('macroeconomics', 0.9477670192718506), ('lifeline', 0.9440898895263672), ('codimension', 0.9428080320358276), ('sustainability', 0.941412627696991), ('naturalization', 0.9316829442977905), ('arena', 0.9310978651046753)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Inspect words with vectors most similar to a given word\n",
    "print(\"Most similar to:\", 'neuroscience')\n",
    "print(vectors2.wv.most_similar('neuroscience'))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar to: Lonza\n",
      "[('Flory', 0.9816685318946838), ('nontransforming', 0.9795741438865662), ('Numerous', 0.9769992828369141), ('SAR324', 0.9755681157112122), ('dictionaries', 0.9745925664901733), ('graphein', 0.9740005731582642), ('discordant', 0.973209798336029), ('Ibn', 0.9724632501602173), ('pyridylmethyl', 0.972217321395874), ('sulfoxides', 0.9721080660820007)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Inspect words with vectors most similar to a given word\n",
    "print(\"Most similar to:\", 'Lonza')\n",
    "print(vectors2.wv.most_similar('Lonza'))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar to: tightly\n",
      "[('spectrally', 0.974089503288269), ('screened', 0.9697147607803345), ('seeding', 0.9688395857810974), ('reversible', 0.9639790654182434), ('sum', 0.9636118412017822), ('periodically', 0.9626333713531494), ('computa', 0.96170574426651), ('inconvenient', 0.9616869688034058), ('prescribed', 0.9607305526733398), ('corrections', 0.9584357142448425)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Inspect words with vectors most similar to a given word\n",
    "print(\"Most similar to:\", 'tightly')\n",
    "print(vectors2.wv.most_similar('tightly'))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-26 13:36:05,065 : INFO : collecting all words and their counts\n",
      "2021-02-26 13:36:05,067 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2021-02-26 13:36:05,624 : INFO : collected 63538 word types from a corpus of 2656274 raw words and 9923 sentences\n",
      "2021-02-26 13:36:05,625 : INFO : Loading a fresh vocabulary\n",
      "2021-02-26 13:36:05,781 : INFO : effective_min_count=5 retains 20752 unique words (32% of original 63538, drops 42786)\n",
      "2021-02-26 13:36:05,782 : INFO : effective_min_count=5 leaves 2585188 word corpus (97% of original 2656274, drops 71086)\n",
      "2021-02-26 13:36:05,888 : INFO : deleting the raw counts dictionary of 63538 items\n",
      "2021-02-26 13:36:05,890 : INFO : sample=0.001 downsamples 26 most-common words\n",
      "2021-02-26 13:36:05,891 : INFO : downsampling leaves estimated 2005620 word corpus (77.6% of prior 2585188)\n",
      "2021-02-26 13:36:05,956 : INFO : estimated required memory for 20752 words and 100 dimensions: 26977600 bytes\n",
      "2021-02-26 13:36:05,957 : INFO : resetting layer weights\n",
      "2021-02-26 13:36:11,658 : INFO : training model with 4 workers on 20752 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2021-02-26 13:36:12,666 : INFO : EPOCH 1 - PROGRESS: at 71.89% examples, 1419962 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 13:36:13,067 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-02-26 13:36:13,068 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-02-26 13:36:13,072 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-02-26 13:36:13,077 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-02-26 13:36:13,078 : INFO : EPOCH - 1 : training on 2656274 raw words (2005182 effective words) took 1.4s, 1415989 effective words/s\n",
      "2021-02-26 13:36:14,084 : INFO : EPOCH 2 - PROGRESS: at 72.61% examples, 1436865 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 13:36:14,463 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-02-26 13:36:14,464 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-02-26 13:36:14,469 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-02-26 13:36:14,473 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-02-26 13:36:14,473 : INFO : EPOCH - 2 : training on 2656274 raw words (2005550 effective words) took 1.4s, 1440367 effective words/s\n",
      "2021-02-26 13:36:15,478 : INFO : EPOCH 3 - PROGRESS: at 71.05% examples, 1408887 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 13:36:15,888 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-02-26 13:36:15,889 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-02-26 13:36:15,894 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-02-26 13:36:15,899 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-02-26 13:36:15,900 : INFO : EPOCH - 3 : training on 2656274 raw words (2005873 effective words) took 1.4s, 1409233 effective words/s\n",
      "2021-02-26 13:36:16,906 : INFO : EPOCH 4 - PROGRESS: at 67.00% examples, 1324424 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 13:36:17,383 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-02-26 13:36:17,384 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-02-26 13:36:17,388 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-02-26 13:36:17,394 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-02-26 13:36:17,395 : INFO : EPOCH - 4 : training on 2656274 raw words (2005517 effective words) took 1.5s, 1343624 effective words/s\n",
      "2021-02-26 13:36:18,399 : INFO : EPOCH 5 - PROGRESS: at 67.71% examples, 1342906 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 13:36:18,872 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-02-26 13:36:18,873 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-02-26 13:36:18,877 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-02-26 13:36:18,884 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-02-26 13:36:18,884 : INFO : EPOCH - 5 : training on 2656274 raw words (2006176 effective words) took 1.5s, 1349448 effective words/s\n",
      "2021-02-26 13:36:18,885 : INFO : training on a 13281370 raw words (10028298 effective words) took 7.2s, 1387816 effective words/s\n"
     ]
    }
   ],
   "source": [
    "vectors3 = gensim.models.Word2Vec(tokenized_text, size=100, min_count=5, sg=0, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_word3 = [list(vectors3.wv.vocab.keys())[(i+1)*1000] for i in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['greatly', 'every', 'includes', 'transcription', 'largest']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed_word3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-26 13:36:24,757 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar to: greatly\n",
      "[('significantly', 0.8782045245170593), ('substantially', 0.7808791399002075), ('dramatically', 0.6995285749435425), ('ultimately', 0.6894906163215637), ('capability', 0.6457507014274597), ('improved', 0.638140082359314), ('enhanced', 0.629065215587616), ('thus', 0.6160373091697693), ('increased', 0.5911352038383484), ('improvements', 0.5893326997756958)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Inspect words with vectors most similar to a given word\n",
    "print(\"Most similar to:\", 'greatly')\n",
    "print(vectors3.wv.most_similar('greatly'))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar to: every\n",
      "[('ten', 0.6816279888153076), ('almost', 0.6725512742996216), ('few', 0.6707489490509033), ('half', 0.6691499352455139), ('except', 0.6654048562049866), ('roughly', 0.663583517074585), ('least', 0.6603336334228516), ('per', 0.6559103727340698), ('old', 0.6518365740776062), ('billion', 0.651665449142456)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Inspect words with vectors most similar to a given word\n",
    "print(\"Most similar to:\", 'every')\n",
    "print(vectors3.wv.most_similar('every'))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar to: includes\n",
      "[('involves', 0.8537815809249878), ('combines', 0.7831259369850159), ('supports', 0.7734456062316895), ('integrates', 0.7514086961746216), ('emphasizes', 0.7439501881599426), ('utilizes', 0.7368146777153015), ('consists', 0.7192471623420715), ('develops', 0.7155880331993103), ('encompasses', 0.7074522972106934), ('explores', 0.6937383413314819)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Inspect words with vectors most similar to a given word\n",
    "print(\"Most similar to:\", 'includes')\n",
    "print(vectors3.wv.most_similar('includes'))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar to: transcription\n",
      "[('eukaryotic', 0.9008668661117554), ('transcriptional', 0.900171160697937), ('replication', 0.8730258941650391), ('receptor', 0.8679792881011963), ('intracellular', 0.859769880771637), ('signaling', 0.8548659086227417), ('cis', 0.8540043234825134), ('putative', 0.847966194152832), ('silencing', 0.841754138469696), ('viral', 0.8399631977081299)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Inspect words with vectors most similar to a given word\n",
    "print(\"Most similar to:\", 'transcription')\n",
    "print(vectors3.wv.most_similar('transcription'))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar to: largest\n",
      "[('oldest', 0.852716326713562), ('earliest', 0.7771295309066772), ('north', 0.7501647472381592), ('province', 0.7465780973434448), ('Appalachian', 0.7434969544410706), ('Great', 0.7431834936141968), ('island', 0.7421600222587585), ('richest', 0.738149881362915), ('Asian', 0.7377354502677917), ('southeastern', 0.7294509410858154)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Inspect words with vectors most similar to a given word\n",
    "print(\"Most similar to:\", 'largest')\n",
    "print(vectors3.wv.most_similar('largest'))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-26 21:46:04,472 : WARNING : consider setting layer size to a multiple of 4 for greater performance\n",
      "2021-02-26 21:46:04,474 : INFO : collecting all words and their counts\n",
      "2021-02-26 21:46:04,475 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2021-02-26 21:46:05,118 : INFO : collected 63538 word types from a corpus of 2656274 raw words and 9923 sentences\n",
      "2021-02-26 21:46:05,119 : INFO : Loading a fresh vocabulary\n",
      "2021-02-26 21:46:16,734 : INFO : effective_min_count=1 retains 63538 unique words (100% of original 63538, drops 0)\n",
      "2021-02-26 21:46:16,736 : INFO : effective_min_count=1 leaves 2656274 word corpus (100% of original 2656274, drops 0)\n",
      "2021-02-26 21:46:17,180 : INFO : deleting the raw counts dictionary of 63538 items\n",
      "2021-02-26 21:46:17,183 : INFO : sample=0.001 downsamples 25 most-common words\n",
      "2021-02-26 21:46:17,184 : INFO : downsampling leaves estimated 2081427 word corpus (78.4% of prior 2656274)\n",
      "2021-02-26 21:46:17,408 : INFO : estimated required memory for 63538 words and 10 dimensions: 36852040 bytes\n",
      "2021-02-26 21:46:17,409 : INFO : resetting layer weights\n",
      "2021-02-26 21:46:38,719 : INFO : training model with 4 workers on 63538 vocabulary and 10 features, using sg=1 hs=0 sample=0.001 negative=5 window=5\n",
      "2021-02-26 21:46:39,727 : INFO : EPOCH 1 - PROGRESS: at 22.66% examples, 460716 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 21:46:40,752 : INFO : EPOCH 1 - PROGRESS: at 42.16% examples, 436702 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 21:46:41,756 : INFO : EPOCH 1 - PROGRESS: at 64.97% examples, 442520 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 21:46:42,759 : INFO : EPOCH 1 - PROGRESS: at 85.80% examples, 441303 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 21:46:43,394 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-02-26 21:46:43,404 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-02-26 21:46:43,406 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-02-26 21:46:43,427 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-02-26 21:46:43,428 : INFO : EPOCH - 1 : training on 2656274 raw words (2082099 effective words) took 4.7s, 442510 effective words/s\n",
      "2021-02-26 21:46:44,474 : INFO : EPOCH 2 - PROGRESS: at 20.11% examples, 391852 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 21:46:45,484 : INFO : EPOCH 2 - PROGRESS: at 38.47% examples, 386255 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 21:46:46,486 : INFO : EPOCH 2 - PROGRESS: at 55.54% examples, 378423 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 21:46:47,504 : INFO : EPOCH 2 - PROGRESS: at 74.29% examples, 376484 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 21:46:48,538 : INFO : EPOCH 2 - PROGRESS: at 91.71% examples, 374217 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 21:46:48,901 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-02-26 21:46:48,929 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-02-26 21:46:48,936 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-02-26 21:46:48,953 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-02-26 21:46:48,954 : INFO : EPOCH - 2 : training on 2656274 raw words (2081026 effective words) took 5.5s, 376793 effective words/s\n",
      "2021-02-26 21:46:50,000 : INFO : EPOCH 3 - PROGRESS: at 18.65% examples, 362900 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 21:46:51,029 : INFO : EPOCH 3 - PROGRESS: at 35.55% examples, 353112 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 21:46:52,050 : INFO : EPOCH 3 - PROGRESS: at 53.31% examples, 358873 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 21:46:53,072 : INFO : EPOCH 3 - PROGRESS: at 72.95% examples, 365311 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 21:46:54,084 : INFO : EPOCH 3 - PROGRESS: at 90.62% examples, 368308 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 21:46:54,555 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-02-26 21:46:54,561 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-02-26 21:46:54,574 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-02-26 21:46:54,590 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-02-26 21:46:54,592 : INFO : EPOCH - 3 : training on 2656274 raw words (2081151 effective words) took 5.6s, 369400 effective words/s\n",
      "2021-02-26 21:46:55,596 : INFO : EPOCH 4 - PROGRESS: at 19.00% examples, 385810 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 21:46:56,619 : INFO : EPOCH 4 - PROGRESS: at 39.12% examples, 399870 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 21:46:57,620 : INFO : EPOCH 4 - PROGRESS: at 59.16% examples, 405513 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 21:46:58,631 : INFO : EPOCH 4 - PROGRESS: at 78.77% examples, 406962 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 21:46:59,644 : INFO : EPOCH 4 - PROGRESS: at 98.11% examples, 404535 words/s, in_qsize 6, out_qsize 0\n",
      "2021-02-26 21:46:59,688 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-02-26 21:46:59,703 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-02-26 21:46:59,719 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-02-26 21:46:59,742 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-02-26 21:46:59,743 : INFO : EPOCH - 4 : training on 2656274 raw words (2082136 effective words) took 5.1s, 404494 effective words/s\n",
      "2021-02-26 21:47:00,793 : INFO : EPOCH 5 - PROGRESS: at 18.65% examples, 361836 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 21:47:01,815 : INFO : EPOCH 5 - PROGRESS: at 36.97% examples, 369089 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 21:47:02,838 : INFO : EPOCH 5 - PROGRESS: at 56.91% examples, 381755 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 21:47:03,857 : INFO : EPOCH 5 - PROGRESS: at 76.19% examples, 384642 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 21:47:04,873 : INFO : EPOCH 5 - PROGRESS: at 93.60% examples, 380560 words/s, in_qsize 8, out_qsize 1\n",
      "2021-02-26 21:47:05,223 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-02-26 21:47:05,233 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-02-26 21:47:05,239 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-02-26 21:47:05,246 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-02-26 21:47:05,247 : INFO : EPOCH - 5 : training on 2656274 raw words (2082719 effective words) took 5.5s, 378661 effective words/s\n",
      "2021-02-26 21:47:05,248 : INFO : training on a 13281370 raw words (10409131 effective words) took 26.5s, 392372 effective words/s\n"
     ]
    }
   ],
   "source": [
    "vectors4 = gensim.models.Word2Vec(tokenized_text, size=10, min_count=1, sg=1, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_word4 = [list(vectors4.wv.vocab.keys())[(i+1)*1000] for i in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['half', 'whether', 'neuroscience', 'Lonza', 'tightly']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed_word4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63538"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(vectors4.wv.vocab.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-26 13:37:38,820 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar to: half\n",
      "[('representing', 0.9732823371887207), ('nearly', 0.972795307636261), ('black', 0.9664586186408997), ('least', 0.9610405564308167), ('few', 0.9545682668685913), ('around', 0.9482489824295044), ('every', 0.9429680705070496), ('covering', 0.9417109489440918), ('over', 0.9415010809898376), ('spanning', 0.940800130367279)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Inspect words with vectors most similar to a given word\n",
    "print(\"Most similar to:\", 'half')\n",
    "print(vectors4.wv.most_similar('half'))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar to: whether\n",
      "[('explain', 0.9642354249954224), ('skew', 0.9559688568115234), ('hypothesized', 0.9536693096160889), ('endogenous', 0.9525479078292847), ('trait', 0.9506796598434448), ('what', 0.9503313899040222), ('ask', 0.9473053812980652), ('if', 0.9449271559715271), ('asymmetry', 0.9439817667007446), ('unknown', 0.9433817267417908)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Inspect words with vectors most similar to a given word\n",
    "print(\"Most similar to:\", 'whether')\n",
    "print(vectors4.wv.most_similar('whether'))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-26 21:50:18,179 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar to: neuroscience\n",
      "[('furthering', 0.9842066764831543), ('informational', 0.9749946594238281), ('relevance', 0.9741153717041016), ('neurobiology', 0.96800696849823), ('interest', 0.9663718342781067), ('informatics', 0.9641363620758057), ('technological', 0.9639126062393188), ('advancing', 0.9617303609848022), ('playing', 0.9597301483154297), ('sciences', 0.9593894481658936)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Inspect words with vectors most similar to a given word\n",
    "print(\"Most similar to:\", 'neuroscience')\n",
    "print(vectors4.wv.most_similar('neuroscience'))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar to: Lonza\n",
      "[('domes', 0.997254490852356), ('Curation', 0.9971436262130737), ('CCC', 0.9964454174041748), ('HPF', 0.9954668283462524), ('ImmunoPrecipitation', 0.9951314330101013), ('Holographic', 0.9947695136070251), ('eyewear', 0.9944987893104553), ('electrogenerated', 0.9944267272949219), ('Quantized', 0.9943544268608093), ('HiSS', 0.9943377375602722)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Inspect words with vectors most similar to a given word\n",
    "print(\"Most similar to:\", 'Lonza')\n",
    "print(vectors4.wv.most_similar('Lonza'))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar to: tightly\n",
      "[('routes', 0.9862256646156311), ('manipulating', 0.9775048494338989), ('tailor', 0.9773040413856506), ('inductive', 0.9732342958450317), ('reverse', 0.9725438952445984), ('render', 0.9721719622612), ('domain', 0.9718952178955078), ('channels', 0.9717416763305664), ('resultant', 0.9705893397331238), ('tuned', 0.9697235226631165)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Inspect words with vectors most similar to a given word\n",
    "print(\"Most similar to:\", 'tightly')\n",
    "print(vectors4.wv.most_similar('tightly'))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-26 13:37:57,083 : INFO : collecting all words and their counts\n",
      "2021-02-26 13:37:57,084 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2021-02-26 13:37:57,617 : INFO : collected 63538 word types from a corpus of 2656274 raw words and 9923 sentences\n",
      "2021-02-26 13:37:57,618 : INFO : Loading a fresh vocabulary\n",
      "2021-02-26 13:37:57,880 : INFO : effective_min_count=1 retains 63538 unique words (100% of original 63538, drops 0)\n",
      "2021-02-26 13:37:57,881 : INFO : effective_min_count=1 leaves 2656274 word corpus (100% of original 2656274, drops 0)\n",
      "2021-02-26 13:37:58,185 : INFO : deleting the raw counts dictionary of 63538 items\n",
      "2021-02-26 13:37:58,188 : INFO : sample=0.001 downsamples 25 most-common words\n",
      "2021-02-26 13:37:58,190 : INFO : downsampling leaves estimated 2081427 word corpus (78.4% of prior 2656274)\n",
      "2021-02-26 13:37:58,373 : INFO : estimated required memory for 63538 words and 100 dimensions: 82599400 bytes\n",
      "2021-02-26 13:37:58,375 : INFO : resetting layer weights\n",
      "2021-02-26 13:38:15,767 : INFO : training model with 4 workers on 63538 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=5\n",
      "2021-02-26 13:38:16,799 : INFO : EPOCH 1 - PROGRESS: at 18.65% examples, 368368 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 13:38:17,814 : INFO : EPOCH 1 - PROGRESS: at 37.74% examples, 381080 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 13:38:18,825 : INFO : EPOCH 1 - PROGRESS: at 56.02% examples, 381302 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 13:38:19,857 : INFO : EPOCH 1 - PROGRESS: at 73.62% examples, 371668 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 13:38:20,859 : INFO : EPOCH 1 - PROGRESS: at 91.71% examples, 375696 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 13:38:21,264 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-02-26 13:38:21,276 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-02-26 13:38:21,314 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-02-26 13:38:21,327 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-02-26 13:38:21,328 : INFO : EPOCH - 1 : training on 2656274 raw words (2081346 effective words) took 5.6s, 374625 effective words/s\n",
      "2021-02-26 13:38:22,334 : INFO : EPOCH 2 - PROGRESS: at 18.29% examples, 369241 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 13:38:23,335 : INFO : EPOCH 2 - PROGRESS: at 35.91% examples, 368836 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 13:38:24,341 : INFO : EPOCH 2 - PROGRESS: at 53.31% examples, 368644 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 13:38:25,373 : INFO : EPOCH 2 - PROGRESS: at 70.68% examples, 360395 words/s, in_qsize 8, out_qsize 0\n",
      "2021-02-26 13:38:26,375 : INFO : EPOCH 2 - PROGRESS: at 85.16% examples, 349906 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 13:38:27,148 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-02-26 13:38:27,159 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-02-26 13:38:27,191 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-02-26 13:38:27,211 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-02-26 13:38:27,212 : INFO : EPOCH - 2 : training on 2656274 raw words (2081176 effective words) took 5.9s, 353883 effective words/s\n",
      "2021-02-26 13:38:28,221 : INFO : EPOCH 3 - PROGRESS: at 15.75% examples, 322230 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 13:38:29,233 : INFO : EPOCH 3 - PROGRESS: at 33.15% examples, 339673 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 13:38:30,286 : INFO : EPOCH 3 - PROGRESS: at 50.62% examples, 343750 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 13:38:31,301 : INFO : EPOCH 3 - PROGRESS: at 62.35% examples, 315270 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 13:38:32,311 : INFO : EPOCH 3 - PROGRESS: at 78.77% examples, 322312 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 13:38:33,344 : INFO : EPOCH 3 - PROGRESS: at 96.52% examples, 328278 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 13:38:33,467 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-02-26 13:38:33,484 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-02-26 13:38:33,515 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-02-26 13:38:33,540 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-02-26 13:38:33,541 : INFO : EPOCH - 3 : training on 2656274 raw words (2082315 effective words) took 6.3s, 329131 effective words/s\n",
      "2021-02-26 13:38:34,547 : INFO : EPOCH 4 - PROGRESS: at 12.71% examples, 261379 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 13:38:35,558 : INFO : EPOCH 4 - PROGRESS: at 30.11% examples, 309922 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 13:38:36,562 : INFO : EPOCH 4 - PROGRESS: at 45.52% examples, 316608 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 13:38:37,582 : INFO : EPOCH 4 - PROGRESS: at 63.08% examples, 322648 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 13:38:38,595 : INFO : EPOCH 4 - PROGRESS: at 78.77% examples, 324976 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 13:38:39,621 : INFO : EPOCH 4 - PROGRESS: at 95.38% examples, 327096 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 13:38:39,832 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-02-26 13:38:39,835 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-02-26 13:38:39,853 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-02-26 13:38:39,889 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-02-26 13:38:39,890 : INFO : EPOCH - 4 : training on 2656274 raw words (2081077 effective words) took 6.3s, 327954 effective words/s\n",
      "2021-02-26 13:38:40,926 : INFO : EPOCH 5 - PROGRESS: at 15.33% examples, 306123 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 13:38:41,938 : INFO : EPOCH 5 - PROGRESS: at 32.32% examples, 327317 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 13:38:42,954 : INFO : EPOCH 5 - PROGRESS: at 48.05% examples, 329446 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 13:38:43,991 : INFO : EPOCH 5 - PROGRESS: at 66.21% examples, 333000 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 13:38:44,994 : INFO : EPOCH 5 - PROGRESS: at 82.74% examples, 335369 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 13:38:45,998 : INFO : EPOCH 5 - PROGRESS: at 98.88% examples, 336894 words/s, in_qsize 4, out_qsize 0\n",
      "2021-02-26 13:38:46,011 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-02-26 13:38:46,020 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-02-26 13:38:46,048 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-02-26 13:38:46,058 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-02-26 13:38:46,059 : INFO : EPOCH - 5 : training on 2656274 raw words (2080982 effective words) took 6.2s, 337469 effective words/s\n",
      "2021-02-26 13:38:46,060 : INFO : training on a 13281370 raw words (10406896 effective words) took 30.3s, 343554 effective words/s\n"
     ]
    }
   ],
   "source": [
    "vectors5 = gensim.models.Word2Vec(tokenized_text, size=100, min_count=1, sg=1, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_word5 = [list(vectors5.wv.vocab.keys())[(i+1)*1000] for i in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['half', 'whether', 'neuroscience', 'Lonza', 'tightly']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed_word5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-26 13:39:16,488 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar to: half\n",
      "[('25', 0.790177583694458), ('80', 0.7899731397628784), ('ten', 0.7695549726486206), ('70', 0.7545516490936279), ('percent', 0.7527369856834412), ('65', 0.749315619468689), ('trillion', 0.7484829425811768), ('About', 0.7458590865135193), ('150', 0.7433521747589111), ('60', 0.7410141229629517)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Inspect words with vectors most similar to a given word\n",
    "print(\"Most similar to:\", 'half')\n",
    "print(vectors5.wv.most_similar('half'))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar to: whether\n",
      "[('if', 0.7773952484130859), ('how', 0.7436619400978088), ('why', 0.705829918384552), ('what', 0.6954272985458374), ('sex', 0.6872129440307617), ('androdioecy', 0.6792768239974976), ('Are', 0.6774872541427612), ('Is', 0.676652729511261), ('Or', 0.6747390031814575), ('ask', 0.6745706796646118)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Inspect words with vectors most similar to a given word\n",
    "print(\"Most similar to:\", 'whether')\n",
    "print(vectors5.wv.most_similar('whether'))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar to: neuroscience\n",
      "[('endocrinology', 0.8928981423377991), ('neurobiology', 0.8739007115364075), ('neuroendocrinology', 0.8608860373497009), ('sociology', 0.8580520749092102), ('linguistics', 0.8549712896347046), ('epidemiology', 0.8538591861724854), ('neurophysiology', 0.8537481427192688), ('revolutionizing', 0.8456230163574219), ('archeology', 0.8387148976325989), ('informs', 0.8276082277297974)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Inspect words with vectors most similar to a given word\n",
    "print(\"Most similar to:\", 'neuroscience')\n",
    "print(vectors5.wv.most_similar('neuroscience'))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar to: Lonza\n",
      "[('04cc', 0.9778331518173218), ('Discover', 0.9769275784492493), ('lampposts', 0.9763314723968506), ('drums', 0.9755334854125977), ('COPS', 0.9749007225036621), ('diaminopropane', 0.9746689796447754), ('lobules', 0.9742003083229065), ('Cytoplamic', 0.9737499952316284), ('mutase', 0.9733877182006836), ('CDV', 0.9733231067657471)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Inspect words with vectors most similar to a given word\n",
    "print(\"Most similar to:\", 'Lonza')\n",
    "print(vectors5.wv.most_similar('Lonza'))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar to: tightly\n",
      "[('loosely', 0.7940118312835693), ('mimic', 0.788912296295166), ('V1', 0.7777059078216553), ('deformable', 0.7661259174346924), ('flexibly', 0.7651008367538452), ('seamlessly', 0.7630290389060974), ('behaviorally', 0.7627905607223511), ('conveniently', 0.762204647064209), ('1D', 0.7617976665496826), ('internally', 0.7611943483352661)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Inspect words with vectors most similar to a given word\n",
    "print(\"Most similar to:\", 'tightly')\n",
    "print(vectors5.wv.most_similar('tightly'))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-26 13:39:46,315 : INFO : collecting all words and their counts\n",
      "2021-02-26 13:39:46,317 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2021-02-26 13:39:46,850 : INFO : collected 63538 word types from a corpus of 2656274 raw words and 9923 sentences\n",
      "2021-02-26 13:39:46,852 : INFO : Loading a fresh vocabulary\n",
      "2021-02-26 13:39:47,018 : INFO : effective_min_count=1 retains 63538 unique words (100% of original 63538, drops 0)\n",
      "2021-02-26 13:39:47,020 : INFO : effective_min_count=1 leaves 2656274 word corpus (100% of original 2656274, drops 0)\n",
      "2021-02-26 13:39:47,319 : INFO : deleting the raw counts dictionary of 63538 items\n",
      "2021-02-26 13:39:47,322 : INFO : sample=0.001 downsamples 25 most-common words\n",
      "2021-02-26 13:39:47,324 : INFO : downsampling leaves estimated 2081427 word corpus (78.4% of prior 2656274)\n",
      "2021-02-26 13:39:47,498 : INFO : estimated required memory for 63538 words and 100 dimensions: 82599400 bytes\n",
      "2021-02-26 13:39:47,500 : INFO : resetting layer weights\n",
      "2021-02-26 13:40:04,571 : INFO : training model with 4 workers on 63538 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2021-02-26 13:40:05,579 : INFO : EPOCH 1 - PROGRESS: at 64.59% examples, 1328588 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 13:40:06,129 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-02-26 13:40:06,131 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-02-26 13:40:06,138 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-02-26 13:40:06,143 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-02-26 13:40:06,143 : INFO : EPOCH - 1 : training on 2656274 raw words (2080440 effective words) took 1.6s, 1326973 effective words/s\n",
      "2021-02-26 13:40:07,148 : INFO : EPOCH 2 - PROGRESS: at 64.59% examples, 1332497 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 13:40:07,686 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-02-26 13:40:07,687 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-02-26 13:40:07,692 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-02-26 13:40:07,699 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-02-26 13:40:07,699 : INFO : EPOCH - 2 : training on 2656274 raw words (2081371 effective words) took 1.6s, 1340202 effective words/s\n",
      "2021-02-26 13:40:08,703 : INFO : EPOCH 3 - PROGRESS: at 63.49% examples, 1310448 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 13:40:09,391 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-02-26 13:40:09,392 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-02-26 13:40:09,396 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-02-26 13:40:09,401 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-02-26 13:40:09,401 : INFO : EPOCH - 3 : training on 2656274 raw words (2081330 effective words) took 1.7s, 1224891 effective words/s\n",
      "2021-02-26 13:40:10,409 : INFO : EPOCH 4 - PROGRESS: at 63.08% examples, 1297291 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 13:40:10,987 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-02-26 13:40:10,988 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-02-26 13:40:10,993 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-02-26 13:40:11,000 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-02-26 13:40:11,000 : INFO : EPOCH - 4 : training on 2656274 raw words (2081534 effective words) took 1.6s, 1304021 effective words/s\n",
      "2021-02-26 13:40:12,009 : INFO : EPOCH 5 - PROGRESS: at 62.35% examples, 1281322 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 13:40:12,618 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-02-26 13:40:12,619 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-02-26 13:40:12,624 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-02-26 13:40:12,631 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-02-26 13:40:12,631 : INFO : EPOCH - 5 : training on 2656274 raw words (2081510 effective words) took 1.6s, 1278856 effective words/s\n",
      "2021-02-26 13:40:12,632 : INFO : training on a 13281370 raw words (10406185 effective words) took 8.1s, 1291192 effective words/s\n"
     ]
    }
   ],
   "source": [
    "vectors6 = gensim.models.Word2Vec(tokenized_text, size=100, min_count=1, sg=0, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_word6 = [list(vectors6.wv.vocab.keys())[(i+1)*1000] for i in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['half', 'whether', 'neuroscience', 'Lonza', 'tightly']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed_word6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-26 13:40:36,736 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar to: half\n",
      "[('80', 0.8614833354949951), ('million', 0.8565804958343506), ('70', 0.8434327840805054), ('percent', 0.8345407247543335), ('25', 0.828275203704834), ('50', 0.822907567024231), ('square', 0.8213421106338501), ('1000', 0.8211793899536133), ('150', 0.8172222375869751), ('days', 0.8170233368873596)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Inspect words with vectors most similar to a given word\n",
    "print(\"Most similar to:\", 'half')\n",
    "print(vectors6.wv.most_similar('half'))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar to: whether\n",
      "[('if', 0.8375376462936401), ('why', 0.8201342225074768), ('how', 0.8175545930862427), ('what', 0.8073095083236694), ('How', 0.7672230005264282), ('bicoordinate', 0.6755235195159912), ('responses', 0.6288872957229614), ('inactivating', 0.6159760355949402), ('sex', 0.6069273948669434), ('Phospho', 0.5972170829772949)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Inspect words with vectors most similar to a given word\n",
    "print(\"Most similar to:\", 'whether')\n",
    "print(vectors6.wv.most_similar('whether'))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar to: neuroscience\n",
      "[('sociology', 0.8529632091522217), ('economics', 0.842451274394989), ('biochemistry', 0.8309021592140198), ('endocrinology', 0.8099850416183472), ('medicine', 0.8027428388595581), ('ecology', 0.7961971759796143), ('conservation', 0.7931435108184814), ('microbiology', 0.7917824983596802), ('oceanography', 0.7916997075080872), ('contemporary', 0.7900481224060059)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Inspect words with vectors most similar to a given word\n",
    "print(\"Most similar to:\", 'neuroscience')\n",
    "print(vectors6.wv.most_similar('neuroscience'))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar to: Lonza\n",
      "[('Rapt', 0.946742057800293), ('Cisco', 0.9320446848869324), ('Serbia', 0.9216082692146301), ('PBD', 0.9192733764648438), ('vegetables', 0.9182940125465393), ('inconsistency', 0.9156026840209961), ('vicariant', 0.9148354530334473), ('Sternoptychidae', 0.9147069454193115), ('0209202', 0.9143208861351013), ('your', 0.9138616919517517)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Inspect words with vectors most similar to a given word\n",
    "print(\"Most similar to:\", 'Lonza')\n",
    "print(vectors6.wv.most_similar('Lonza'))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar to: tightly\n",
      "[('structurally', 0.8403840065002441), ('intrinsically', 0.8381390571594238), ('weakly', 0.8356295824050903), ('deformable', 0.8241686224937439), ('tunnels', 0.8216641545295715), ('gates', 0.8200643658638), ('functionally', 0.8147437572479248), ('mechanically', 0.8121119737625122), ('intimately', 0.8119672536849976), ('clustered', 0.8089224100112915)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Inspect words with vectors most similar to a given word\n",
    "print(\"Most similar to:\", 'tightly')\n",
    "print(vectors6.wv.most_similar('tightly'))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-26 13:40:50,348 : WARNING : consider setting layer size to a multiple of 4 for greater performance\n",
      "2021-02-26 13:40:50,350 : INFO : collecting all words and their counts\n",
      "2021-02-26 13:40:50,351 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2021-02-26 13:40:50,889 : INFO : collected 63538 word types from a corpus of 2656274 raw words and 9923 sentences\n",
      "2021-02-26 13:40:50,891 : INFO : Loading a fresh vocabulary\n",
      "2021-02-26 13:40:51,080 : INFO : effective_min_count=5 retains 20752 unique words (32% of original 63538, drops 42786)\n",
      "2021-02-26 13:40:51,082 : INFO : effective_min_count=5 leaves 2585188 word corpus (97% of original 2656274, drops 71086)\n",
      "2021-02-26 13:40:51,182 : INFO : deleting the raw counts dictionary of 63538 items\n",
      "2021-02-26 13:40:51,186 : INFO : sample=0.001 downsamples 26 most-common words\n",
      "2021-02-26 13:40:51,187 : INFO : downsampling leaves estimated 2005620 word corpus (77.6% of prior 2585188)\n",
      "2021-02-26 13:40:51,244 : INFO : estimated required memory for 20752 words and 10 dimensions: 12036160 bytes\n",
      "2021-02-26 13:40:51,245 : INFO : resetting layer weights\n",
      "2021-02-26 13:40:56,914 : INFO : training model with 4 workers on 20752 vocabulary and 10 features, using sg=1 hs=0 sample=0.001 negative=5 window=5\n",
      "2021-02-26 13:40:57,928 : INFO : EPOCH 1 - PROGRESS: at 27.66% examples, 545890 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 13:40:58,931 : INFO : EPOCH 1 - PROGRESS: at 56.53% examples, 561235 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 13:40:59,936 : INFO : EPOCH 1 - PROGRESS: at 85.16% examples, 563940 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 13:41:00,444 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-02-26 13:41:00,448 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-02-26 13:41:00,455 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-02-26 13:41:00,473 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-02-26 13:41:00,474 : INFO : EPOCH - 1 : training on 2656274 raw words (2005645 effective words) took 3.6s, 564188 effective words/s\n",
      "2021-02-26 13:41:01,478 : INFO : EPOCH 2 - PROGRESS: at 27.33% examples, 543010 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 13:41:02,482 : INFO : EPOCH 2 - PROGRESS: at 54.70% examples, 548703 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 13:41:03,490 : INFO : EPOCH 2 - PROGRESS: at 82.34% examples, 544837 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 13:41:04,304 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-02-26 13:41:04,306 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-02-26 13:41:04,325 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-02-26 13:41:04,342 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-02-26 13:41:04,344 : INFO : EPOCH - 2 : training on 2656274 raw words (2005800 effective words) took 3.9s, 518760 effective words/s\n",
      "2021-02-26 13:41:05,373 : INFO : EPOCH 3 - PROGRESS: at 24.44% examples, 470461 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 13:41:06,379 : INFO : EPOCH 3 - PROGRESS: at 47.34% examples, 471225 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 13:41:07,393 : INFO : EPOCH 3 - PROGRESS: at 74.29% examples, 485113 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 13:41:08,406 : INFO : EPOCH 3 - PROGRESS: at 89.26% examples, 440978 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 13:41:08,818 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-02-26 13:41:08,828 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-02-26 13:41:08,849 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-02-26 13:41:08,850 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-02-26 13:41:08,851 : INFO : EPOCH - 3 : training on 2656274 raw words (2005248 effective words) took 4.5s, 445200 effective words/s\n",
      "2021-02-26 13:41:09,856 : INFO : EPOCH 4 - PROGRESS: at 26.19% examples, 519246 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 13:41:10,885 : INFO : EPOCH 4 - PROGRESS: at 52.27% examples, 515230 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 13:41:11,892 : INFO : EPOCH 4 - PROGRESS: at 76.80% examples, 505908 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 13:41:12,900 : INFO : EPOCH 4 - PROGRESS: at 92.91% examples, 460582 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 13:41:13,138 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-02-26 13:41:13,145 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-02-26 13:41:13,163 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-02-26 13:41:13,170 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-02-26 13:41:13,171 : INFO : EPOCH - 4 : training on 2656274 raw words (2005691 effective words) took 4.3s, 464597 effective words/s\n",
      "2021-02-26 13:41:14,203 : INFO : EPOCH 5 - PROGRESS: at 25.85% examples, 498237 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 13:41:15,210 : INFO : EPOCH 5 - PROGRESS: at 51.03% examples, 503284 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 13:41:16,214 : INFO : EPOCH 5 - PROGRESS: at 67.00% examples, 437527 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 13:41:17,229 : INFO : EPOCH 5 - PROGRESS: at 92.53% examples, 457845 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 13:41:17,477 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-02-26 13:41:17,481 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-02-26 13:41:17,493 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-02-26 13:41:17,518 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-02-26 13:41:17,520 : INFO : EPOCH - 5 : training on 2656274 raw words (2005908 effective words) took 4.3s, 461508 effective words/s\n",
      "2021-02-26 13:41:17,522 : INFO : training on a 13281370 raw words (10028292 effective words) took 20.6s, 486638 effective words/s\n"
     ]
    }
   ],
   "source": [
    "vectors7 = gensim.models.Word2Vec(tokenized_text, size=10, min_count=5, sg=1, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_word7 = [list(vectors7.wv.vocab.keys())[(i+1)*1000] for i in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['greatly', 'every', 'includes', 'transcription', 'largest']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed_word7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-26 14:04:14,419 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar to: greatly\n",
      "[('significantly', 0.9823163747787476), ('aid', 0.9707620143890381), ('ability', 0.9605613350868225), ('improved', 0.9523959159851074), ('linking', 0.9482380151748657), ('assessing', 0.9464660286903381), ('improvement', 0.9447351694107056), ('facilitating', 0.9437584280967712), ('participatory', 0.9437243938446045), ('Identify', 0.9425539970397949)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Inspect words with vectors most similar to a given word\n",
    "print(\"Most similar to:\", 'greatly')\n",
    "print(vectors7.wv.most_similar('greatly'))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar to: every\n",
      "[('one', 0.9544808864593506), ('forty', 0.9348524212837219), ('fifty', 0.9336089491844177), ('least', 0.9320022463798523), ('attracts', 0.9301199316978455), ('round', 0.9274606108665466), ('hold', 0.9169936180114746), ('given', 0.916497528553009), ('holding', 0.9150835871696472), ('ample', 0.9130387902259827)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Inspect words with vectors most similar to a given word\n",
    "print(\"Most similar to:\", 'every')\n",
    "print(vectors7.wv.most_similar('every'))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar to: includes\n",
      "[('include', 0.9577757120132446), ('The', 0.9568184614181519), ('an', 0.9527792930603027), ('involves', 0.9490988850593567), ('Primary', 0.9430201649665833), ('for', 0.9428271055221558), ('comprises', 0.9396464228630066), ('Conduct', 0.9395472407341003), ('Through', 0.9394429922103882), ('on', 0.9357964396476746)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Inspect words with vectors most similar to a given word\n",
    "print(\"Most similar to:\", 'includes')\n",
    "print(vectors7.wv.most_similar('includes'))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar to: transcription\n",
      "[('regulated', 0.98469078540802), ('replication', 0.9833722710609436), ('receptor', 0.9808540940284729), ('gene', 0.9795259237289429), ('signaling', 0.9783895015716553), ('splicing', 0.9763568043708801), ('pathway', 0.9750600457191467), ('silencing', 0.9727146625518799), ('secretion', 0.970633864402771), ('chloroplast', 0.9689313173294067)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Inspect words with vectors most similar to a given word\n",
    "print(\"Most similar to:\", 'transcription')\n",
    "print(vectors7.wv.most_similar('transcription'))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar to: largest\n",
      "[('Saharan', 0.9502067565917969), ('mountainous', 0.9391655325889587), ('border', 0.935000479221344), ('northeastern', 0.9338515996932983), ('towns', 0.9337120056152344), ('southeastern', 0.9299823045730591), ('gatherer', 0.9286332726478577), ('1970s', 0.9252861738204956), ('deserts', 0.924917995929718), ('biomes', 0.9243955016136169)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Inspect words with vectors most similar to a given word\n",
    "print(\"Most similar to:\", 'largest')\n",
    "print(vectors7.wv.most_similar('largest'))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-26 14:04:22,539 : WARNING : consider setting layer size to a multiple of 4 for greater performance\n",
      "2021-02-26 14:04:22,542 : INFO : collecting all words and their counts\n",
      "2021-02-26 14:04:22,542 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2021-02-26 14:04:23,112 : INFO : collected 63538 word types from a corpus of 2656274 raw words and 9923 sentences\n",
      "2021-02-26 14:04:23,113 : INFO : Loading a fresh vocabulary\n",
      "2021-02-26 14:04:23,189 : INFO : effective_min_count=5 retains 20752 unique words (32% of original 63538, drops 42786)\n",
      "2021-02-26 14:04:23,190 : INFO : effective_min_count=5 leaves 2585188 word corpus (97% of original 2656274, drops 71086)\n",
      "2021-02-26 14:04:23,298 : INFO : deleting the raw counts dictionary of 63538 items\n",
      "2021-02-26 14:04:23,300 : INFO : sample=0.001 downsamples 26 most-common words\n",
      "2021-02-26 14:04:23,301 : INFO : downsampling leaves estimated 2005620 word corpus (77.6% of prior 2585188)\n",
      "2021-02-26 14:04:23,360 : INFO : estimated required memory for 20752 words and 10 dimensions: 12036160 bytes\n",
      "2021-02-26 14:04:23,361 : INFO : resetting layer weights\n",
      "2021-02-26 14:04:29,040 : INFO : training model with 4 workers on 20752 vocabulary and 10 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2021-02-26 14:04:30,047 : INFO : EPOCH 1 - PROGRESS: at 92.11% examples, 1843059 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 14:04:30,128 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-02-26 14:04:30,128 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-02-26 14:04:30,132 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-02-26 14:04:30,135 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-02-26 14:04:30,136 : INFO : EPOCH - 1 : training on 2656274 raw words (2005643 effective words) took 1.1s, 1836329 effective words/s\n",
      "2021-02-26 14:04:31,140 : INFO : EPOCH 2 - PROGRESS: at 85.46% examples, 1706319 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 14:04:31,323 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-02-26 14:04:31,324 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-02-26 14:04:31,328 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-02-26 14:04:31,332 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-02-26 14:04:31,332 : INFO : EPOCH - 2 : training on 2656274 raw words (2005967 effective words) took 1.2s, 1680467 effective words/s\n",
      "2021-02-26 14:04:32,344 : INFO : EPOCH 3 - PROGRESS: at 79.24% examples, 1576572 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 14:04:32,612 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-02-26 14:04:32,614 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-02-26 14:04:32,617 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-02-26 14:04:32,622 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-02-26 14:04:32,623 : INFO : EPOCH - 3 : training on 2656274 raw words (2005277 effective words) took 1.3s, 1557944 effective words/s\n",
      "2021-02-26 14:04:33,629 : INFO : EPOCH 4 - PROGRESS: at 76.53% examples, 1525854 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 14:04:33,939 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-02-26 14:04:33,940 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-02-26 14:04:33,944 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-02-26 14:04:33,949 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-02-26 14:04:33,950 : INFO : EPOCH - 4 : training on 2656274 raw words (2005703 effective words) took 1.3s, 1514864 effective words/s\n",
      "2021-02-26 14:04:34,956 : INFO : EPOCH 5 - PROGRESS: at 81.91% examples, 1627941 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 14:04:35,177 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-02-26 14:04:35,178 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-02-26 14:04:35,182 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-02-26 14:04:35,185 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-02-26 14:04:35,186 : INFO : EPOCH - 5 : training on 2656274 raw words (2005364 effective words) took 1.2s, 1626801 effective words/s\n",
      "2021-02-26 14:04:35,186 : INFO : training on a 13281370 raw words (10027954 effective words) took 6.1s, 1631886 effective words/s\n"
     ]
    }
   ],
   "source": [
    "vectors8 = gensim.models.Word2Vec(tokenized_text, size=10, min_count=5, sg=0, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "seed_word8 = [list(vectors8.wv.vocab.keys())[(i+1)*1000] for i in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['greatly', 'every', 'includes', 'transcription', 'largest']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed_word8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-26 14:04:45,154 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar to: greatly\n",
      "[('significantly', 0.9625788331031799), ('ability', 0.9101622104644775), ('substantially', 0.8781238794326782), ('to', 0.8764215707778931), ('necessary', 0.8735238313674927), ('us', 0.8630886077880859), ('better', 0.8587857484817505), ('effectively', 0.8520721793174744), ('strategies', 0.850286602973938), ('should', 0.8486435413360596)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Inspect words with vectors most similar to a given word\n",
    "print(\"Most similar to:\", 'greatly')\n",
    "print(vectors8.wv.most_similar('greatly'))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar to: every\n",
      "[('later', 0.924665093421936), ('few', 0.9168813824653625), ('classified', 0.9053330421447754), ('chosen', 0.8952016830444336), ('thirty', 0.8723949193954468), ('rarely', 0.8720383644104004), ('just', 0.8637912273406982), ('inaccessible', 0.8631974458694458), ('millions', 0.8623626232147217), ('least', 0.8604147434234619)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Inspect words with vectors most similar to a given word\n",
    "print(\"Most similar to:\", 'every')\n",
    "print(vectors8.wv.most_similar('every'))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar to: includes\n",
      "[('involves', 0.9217371344566345), ('include', 0.9062110781669617), ('combines', 0.8593859672546387), ('capitalizes', 0.8403268456459045), ('consists', 0.8359469771385193), ('provides', 0.8328524231910706), ('emphasize', 0.826043426990509), ('supports', 0.8258134126663208), ('brings', 0.8222417831420898), ('upon', 0.8124222755432129)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Inspect words with vectors most similar to a given word\n",
    "print(\"Most similar to:\", 'includes')\n",
    "print(vectors8.wv.most_similar('includes'))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar to: transcription\n",
      "[('receptor', 0.9635428786277771), ('galaxy', 0.9552401900291443), ('eukaryotic', 0.9497318267822266), ('mRNA', 0.9465463161468506), ('transcriptional', 0.9457406997680664), ('MHC', 0.9427085518836975), ('muscle', 0.9385768175125122), ('conserved', 0.9299783110618591), ('silencing', 0.9290547370910645), ('phenotypic', 0.9256062507629395)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Inspect words with vectors most similar to a given word\n",
    "print(\"Most similar to:\", 'transcription')\n",
    "print(vectors8.wv.most_similar('transcription'))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar to: largest\n",
      "[('North', 0.9387719631195068), ('earliest', 0.923382043838501), ('America', 0.9213746190071106), ('eighteenth', 0.9158466458320618), ('gatherers', 0.9120859503746033), ('Asian', 0.908501148223877), ('Andean', 0.9053014516830444), ('Asia', 0.902595043182373), ('island', 0.8988133668899536), ('19th', 0.8920904397964478)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Inspect words with vectors most similar to a given word\n",
    "print(\"Most similar to:\", 'largest')\n",
    "print(vectors8.wv.most_similar('largest'))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QUESTION 2B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of abstracts in folder awards: 132372\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import os\n",
    "import re\n",
    "\n",
    "def get_fnames():\n",
    "    \"\"\"Read all text files in a folder.\n",
    "    \"\"\"\n",
    "    fnames = []\n",
    "    for root,_,files in os.walk(\"./abstracts\"):\n",
    "        for fname in files:\n",
    "            if fname[-4:] == \".txt\":\n",
    "                fnames.append(os.path.join(root, fname))\n",
    "    return fnames\n",
    "\n",
    "print(\"Number of abstracts in folder awards: {}\".format(len(get_fnames())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_list = get_fnames()\n",
    "\n",
    "def read_file(fname):\n",
    "    with open(fname, 'r',encoding=\"ISO-8859-1\") as f:\n",
    "        # skip all lines until abstract\n",
    "        for line in f:\n",
    "            if \"Abstract    :\" in line:\n",
    "                break\n",
    "\n",
    "        # get abstract as a single string\n",
    "        abstract = ' '.join([line[:-1].strip() for line in f])\n",
    "        abstract = re.sub(' +', ' ', abstract)  # remove double spaces\n",
    "        return abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents_full = []\n",
    "\n",
    "for i in name_list:\n",
    "    documents_full.append(read_file(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_vectorizer1 = TfidfVectorizer(stop_words = 'english', lowercase= True, ngram_range = (1,3) ,min_df=5, use_idf=True, sublinear_tf=True, max_df=1.0)\n",
    "word_tokenizer1 = new_vectorizer1.build_tokenizer()\n",
    "tokenized_text1 = [word_tokenizer1(doc) for doc in documents_full]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_text1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "132372"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenized_text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-26 21:56:34,045 : WARNING : consider setting layer size to a multiple of 4 for greater performance\n",
      "2021-02-26 21:56:34,048 : INFO : collecting all words and their counts\n",
      "2021-02-26 21:56:34,049 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2021-02-26 21:56:34,422 : INFO : PROGRESS: at sentence #10000, processed 1565323 words, keeping 47155 word types\n",
      "2021-02-26 21:56:34,922 : INFO : PROGRESS: at sentence #20000, processed 3528075 words, keeping 79367 word types\n",
      "2021-02-26 21:56:35,403 : INFO : PROGRESS: at sentence #30000, processed 5442667 words, keeping 105577 word types\n",
      "2021-02-26 21:56:35,944 : INFO : PROGRESS: at sentence #40000, processed 7205533 words, keeping 127561 word types\n",
      "2021-02-26 21:56:36,840 : INFO : PROGRESS: at sentence #50000, processed 9646664 words, keeping 149006 word types\n",
      "2021-02-26 21:56:37,624 : INFO : PROGRESS: at sentence #60000, processed 12202268 words, keeping 167318 word types\n",
      "2021-02-26 21:56:38,278 : INFO : PROGRESS: at sentence #70000, processed 14413047 words, keeping 184849 word types\n",
      "2021-02-26 21:56:38,745 : INFO : PROGRESS: at sentence #80000, processed 15940674 words, keeping 192628 word types\n",
      "2021-02-26 21:56:39,359 : INFO : PROGRESS: at sentence #90000, processed 18069977 words, keeping 207107 word types\n",
      "2021-02-26 21:56:40,049 : INFO : PROGRESS: at sentence #100000, processed 20465250 words, keeping 221416 word types\n",
      "2021-02-26 21:56:40,529 : INFO : PROGRESS: at sentence #110000, processed 22124882 words, keeping 229369 word types\n",
      "2021-02-26 21:56:41,135 : INFO : PROGRESS: at sentence #120000, processed 24160301 words, keeping 241454 word types\n",
      "2021-02-26 21:56:41,904 : INFO : PROGRESS: at sentence #130000, processed 26729522 words, keeping 254009 word types\n",
      "2021-02-26 21:56:42,108 : INFO : collected 257022 word types from a corpus of 27374377 raw words and 132372 sentences\n",
      "2021-02-26 21:56:42,110 : INFO : Loading a fresh vocabulary\n",
      "2021-02-26 21:56:42,996 : INFO : effective_min_count=1 retains 257022 unique words (100% of original 257022, drops 0)\n",
      "2021-02-26 21:56:42,997 : INFO : effective_min_count=1 leaves 27374377 word corpus (100% of original 27374377, drops 0)\n",
      "2021-02-26 21:56:44,556 : INFO : deleting the raw counts dictionary of 257022 items\n",
      "2021-02-26 21:56:44,565 : INFO : sample=0.001 downsamples 25 most-common words\n",
      "2021-02-26 21:56:44,566 : INFO : downsampling leaves estimated 21283036 word corpus (77.7% of prior 27374377)\n",
      "2021-02-26 21:56:45,478 : INFO : estimated required memory for 257022 words and 10 dimensions: 149072760 bytes\n",
      "2021-02-26 21:56:45,479 : INFO : resetting layer weights\n",
      "2021-02-26 21:58:09,406 : INFO : training model with 4 workers on 257022 vocabulary and 10 features, using sg=1 hs=0 sample=0.001 negative=5 window=5\n",
      "2021-02-26 21:58:10,424 : INFO : EPOCH 1 - PROGRESS: at 2.38% examples, 340353 words/s, in_qsize 8, out_qsize 0\n",
      "2021-02-26 21:58:11,427 : INFO : EPOCH 1 - PROGRESS: at 4.47% examples, 348160 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 21:58:12,438 : INFO : EPOCH 1 - PROGRESS: at 6.84% examples, 355695 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 21:58:13,445 : INFO : EPOCH 1 - PROGRESS: at 8.90% examples, 361260 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 21:58:14,449 : INFO : EPOCH 1 - PROGRESS: at 10.55% examples, 360997 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 21:58:15,449 : INFO : EPOCH 1 - PROGRESS: at 12.33% examples, 361085 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 21:58:16,460 : INFO : EPOCH 1 - PROGRESS: at 14.04% examples, 361233 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 21:58:17,472 : INFO : EPOCH 1 - PROGRESS: at 15.92% examples, 360560 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 21:58:18,486 : INFO : EPOCH 1 - PROGRESS: at 17.65% examples, 359799 words/s, in_qsize 8, out_qsize 0\n",
      "2021-02-26 21:58:19,507 : INFO : EPOCH 1 - PROGRESS: at 19.10% examples, 350186 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 21:58:20,521 : INFO : EPOCH 1 - PROGRESS: at 20.92% examples, 349824 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 21:58:21,552 : INFO : EPOCH 1 - PROGRESS: at 22.86% examples, 350474 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 21:58:22,569 : INFO : EPOCH 1 - PROGRESS: at 24.93% examples, 349707 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 21:58:23,590 : INFO : EPOCH 1 - PROGRESS: at 26.79% examples, 348174 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 21:58:24,608 : INFO : EPOCH 1 - PROGRESS: at 28.63% examples, 346645 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 21:58:25,636 : INFO : EPOCH 1 - PROGRESS: at 30.39% examples, 346394 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 21:58:26,637 : INFO : EPOCH 1 - PROGRESS: at 31.70% examples, 344965 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 21:58:27,642 : INFO : EPOCH 1 - PROGRESS: at 32.98% examples, 344428 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 21:58:28,649 : INFO : EPOCH 1 - PROGRESS: at 34.44% examples, 344419 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 21:58:29,659 : INFO : EPOCH 1 - PROGRESS: at 35.67% examples, 343511 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 21:58:30,676 : INFO : EPOCH 1 - PROGRESS: at 37.08% examples, 343641 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 21:58:31,679 : INFO : EPOCH 1 - PROGRESS: at 38.40% examples, 343344 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 21:58:32,682 : INFO : EPOCH 1 - PROGRESS: at 39.66% examples, 342812 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 21:58:33,690 : INFO : EPOCH 1 - PROGRESS: at 40.96% examples, 342475 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 21:58:34,695 : INFO : EPOCH 1 - PROGRESS: at 42.17% examples, 342267 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 21:58:35,697 : INFO : EPOCH 1 - PROGRESS: at 43.43% examples, 342078 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 21:58:36,700 : INFO : EPOCH 1 - PROGRESS: at 44.80% examples, 342456 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 21:58:37,721 : INFO : EPOCH 1 - PROGRESS: at 46.00% examples, 341426 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 21:58:38,755 : INFO : EPOCH 1 - PROGRESS: at 47.19% examples, 339801 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 21:58:39,760 : INFO : EPOCH 1 - PROGRESS: at 48.62% examples, 338886 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 21:58:40,796 : INFO : EPOCH 1 - PROGRESS: at 49.72% examples, 335506 words/s, in_qsize 5, out_qsize 2\n",
      "2021-02-26 21:58:41,821 : INFO : EPOCH 1 - PROGRESS: at 51.20% examples, 335388 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 21:58:42,835 : INFO : EPOCH 1 - PROGRESS: at 52.89% examples, 335297 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 21:58:43,838 : INFO : EPOCH 1 - PROGRESS: at 54.80% examples, 335039 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 21:58:44,849 : INFO : EPOCH 1 - PROGRESS: at 57.01% examples, 334760 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 21:58:45,868 : INFO : EPOCH 1 - PROGRESS: at 59.22% examples, 334601 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 21:58:46,875 : INFO : EPOCH 1 - PROGRESS: at 61.47% examples, 334583 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 21:58:47,895 : INFO : EPOCH 1 - PROGRESS: at 63.06% examples, 334893 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 21:58:48,909 : INFO : EPOCH 1 - PROGRESS: at 64.39% examples, 334837 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 21:58:49,933 : INFO : EPOCH 1 - PROGRESS: at 65.98% examples, 334694 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 21:58:50,940 : INFO : EPOCH 1 - PROGRESS: at 67.37% examples, 334868 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 21:58:51,969 : INFO : EPOCH 1 - PROGRESS: at 68.76% examples, 334202 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 21:58:52,975 : INFO : EPOCH 1 - PROGRESS: at 70.05% examples, 334436 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 21:58:53,994 : INFO : EPOCH 1 - PROGRESS: at 71.43% examples, 334226 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 21:58:55,007 : INFO : EPOCH 1 - PROGRESS: at 72.86% examples, 334197 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 21:58:56,021 : INFO : EPOCH 1 - PROGRESS: at 74.15% examples, 333838 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 21:58:57,033 : INFO : EPOCH 1 - PROGRESS: at 75.50% examples, 333827 words/s, in_qsize 8, out_qsize 0\n",
      "2021-02-26 21:58:58,036 : INFO : EPOCH 1 - PROGRESS: at 77.05% examples, 333905 words/s, in_qsize 7, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-26 21:58:59,064 : INFO : EPOCH 1 - PROGRESS: at 79.08% examples, 333728 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 21:59:00,070 : INFO : EPOCH 1 - PROGRESS: at 81.21% examples, 333726 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 21:59:01,081 : INFO : EPOCH 1 - PROGRESS: at 83.51% examples, 333543 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 21:59:02,110 : INFO : EPOCH 1 - PROGRESS: at 85.22% examples, 333409 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 21:59:03,139 : INFO : EPOCH 1 - PROGRESS: at 86.83% examples, 333327 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 21:59:04,169 : INFO : EPOCH 1 - PROGRESS: at 88.40% examples, 333333 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 21:59:05,191 : INFO : EPOCH 1 - PROGRESS: at 89.84% examples, 333297 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 21:59:06,217 : INFO : EPOCH 1 - PROGRESS: at 91.39% examples, 333259 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 21:59:07,227 : INFO : EPOCH 1 - PROGRESS: at 92.67% examples, 332987 words/s, in_qsize 8, out_qsize 0\n",
      "2021-02-26 21:59:08,238 : INFO : EPOCH 1 - PROGRESS: at 93.91% examples, 332888 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 21:59:09,263 : INFO : EPOCH 1 - PROGRESS: at 95.06% examples, 332571 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 21:59:10,265 : INFO : EPOCH 1 - PROGRESS: at 96.01% examples, 331662 words/s, in_qsize 6, out_qsize 1\n",
      "2021-02-26 21:59:11,271 : INFO : EPOCH 1 - PROGRESS: at 96.99% examples, 330497 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 21:59:12,326 : INFO : EPOCH 1 - PROGRESS: at 98.18% examples, 330101 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 21:59:13,405 : INFO : EPOCH 1 - PROGRESS: at 99.17% examples, 328968 words/s, in_qsize 6, out_qsize 3\n",
      "2021-02-26 21:59:13,995 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-02-26 21:59:14,064 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-02-26 21:59:14,084 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-02-26 21:59:14,088 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-02-26 21:59:14,088 : INFO : EPOCH - 1 : training on 27374377 raw words (21281190 effective words) took 64.7s, 329039 effective words/s\n",
      "2021-02-26 21:59:15,117 : INFO : EPOCH 2 - PROGRESS: at 2.22% examples, 306369 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 21:59:16,126 : INFO : EPOCH 2 - PROGRESS: at 4.13% examples, 318831 words/s, in_qsize 8, out_qsize 0\n",
      "2021-02-26 21:59:17,130 : INFO : EPOCH 2 - PROGRESS: at 6.31% examples, 324027 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 21:59:18,148 : INFO : EPOCH 2 - PROGRESS: at 8.26% examples, 327328 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 21:59:19,149 : INFO : EPOCH 2 - PROGRESS: at 9.85% examples, 328841 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 21:59:20,150 : INFO : EPOCH 2 - PROGRESS: at 11.58% examples, 329475 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 21:59:21,165 : INFO : EPOCH 2 - PROGRESS: at 13.06% examples, 329899 words/s, in_qsize 8, out_qsize 0\n",
      "2021-02-26 21:59:22,170 : INFO : EPOCH 2 - PROGRESS: at 14.74% examples, 329408 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 21:59:23,181 : INFO : EPOCH 2 - PROGRESS: at 16.16% examples, 325523 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 21:59:24,220 : INFO : EPOCH 2 - PROGRESS: at 17.83% examples, 325297 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 21:59:25,248 : INFO : EPOCH 2 - PROGRESS: at 19.62% examples, 325712 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 21:59:26,277 : INFO : EPOCH 2 - PROGRESS: at 21.35% examples, 325861 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 21:59:27,299 : INFO : EPOCH 2 - PROGRESS: at 23.13% examples, 326246 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 21:59:28,364 : INFO : EPOCH 2 - PROGRESS: at 25.21% examples, 326177 words/s, in_qsize 8, out_qsize 0\n",
      "2021-02-26 21:59:29,423 : INFO : EPOCH 2 - PROGRESS: at 26.75% examples, 321528 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 21:59:30,467 : INFO : EPOCH 2 - PROGRESS: at 27.99% examples, 314647 words/s, in_qsize 6, out_qsize 1\n",
      "2021-02-26 21:59:31,501 : INFO : EPOCH 2 - PROGRESS: at 29.39% examples, 311416 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 21:59:32,513 : INFO : EPOCH 2 - PROGRESS: at 30.75% examples, 309245 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 21:59:33,526 : INFO : EPOCH 2 - PROGRESS: at 31.60% examples, 304572 words/s, in_qsize 8, out_qsize 0\n",
      "2021-02-26 21:59:34,554 : INFO : EPOCH 2 - PROGRESS: at 32.65% examples, 302791 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 21:59:35,575 : INFO : EPOCH 2 - PROGRESS: at 33.70% examples, 299815 words/s, in_qsize 8, out_qsize 1\n",
      "2021-02-26 21:59:36,578 : INFO : EPOCH 2 - PROGRESS: at 34.95% examples, 300471 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 21:59:37,587 : INFO : EPOCH 2 - PROGRESS: at 36.18% examples, 301956 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 21:59:38,623 : INFO : EPOCH 2 - PROGRESS: at 37.58% examples, 303262 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 21:59:39,639 : INFO : EPOCH 2 - PROGRESS: at 38.95% examples, 304745 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 21:59:40,666 : INFO : EPOCH 2 - PROGRESS: at 40.18% examples, 305707 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 21:59:41,671 : INFO : EPOCH 2 - PROGRESS: at 41.44% examples, 306554 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 21:59:42,727 : INFO : EPOCH 2 - PROGRESS: at 42.56% examples, 305749 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 21:59:43,747 : INFO : EPOCH 2 - PROGRESS: at 43.76% examples, 306082 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 21:59:44,759 : INFO : EPOCH 2 - PROGRESS: at 45.00% examples, 306480 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 21:59:45,768 : INFO : EPOCH 2 - PROGRESS: at 46.26% examples, 307336 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 21:59:46,771 : INFO : EPOCH 2 - PROGRESS: at 47.63% examples, 308163 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 21:59:47,784 : INFO : EPOCH 2 - PROGRESS: at 49.11% examples, 308928 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 21:59:48,785 : INFO : EPOCH 2 - PROGRESS: at 50.66% examples, 309748 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 21:59:49,790 : INFO : EPOCH 2 - PROGRESS: at 52.25% examples, 310716 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 21:59:50,824 : INFO : EPOCH 2 - PROGRESS: at 54.22% examples, 311332 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 21:59:51,833 : INFO : EPOCH 2 - PROGRESS: at 56.39% examples, 312061 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 21:59:52,855 : INFO : EPOCH 2 - PROGRESS: at 58.57% examples, 312716 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 21:59:53,900 : INFO : EPOCH 2 - PROGRESS: at 61.11% examples, 313332 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 21:59:54,919 : INFO : EPOCH 2 - PROGRESS: at 62.81% examples, 314160 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 21:59:55,959 : INFO : EPOCH 2 - PROGRESS: at 64.22% examples, 314763 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 21:59:56,998 : INFO : EPOCH 2 - PROGRESS: at 65.71% examples, 315005 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 21:59:58,028 : INFO : EPOCH 2 - PROGRESS: at 67.01% examples, 314579 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 21:59:59,034 : INFO : EPOCH 2 - PROGRESS: at 68.43% examples, 314722 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:00:00,053 : INFO : EPOCH 2 - PROGRESS: at 69.69% examples, 314799 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:00:01,079 : INFO : EPOCH 2 - PROGRESS: at 71.01% examples, 315130 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:00:02,095 : INFO : EPOCH 2 - PROGRESS: at 72.34% examples, 314861 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:00:03,105 : INFO : EPOCH 2 - PROGRESS: at 73.62% examples, 314957 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:00:04,108 : INFO : EPOCH 2 - PROGRESS: at 75.01% examples, 315549 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:00:05,135 : INFO : EPOCH 2 - PROGRESS: at 76.42% examples, 315695 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:00:06,137 : INFO : EPOCH 2 - PROGRESS: at 78.31% examples, 316040 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:00:07,149 : INFO : EPOCH 2 - PROGRESS: at 80.45% examples, 316349 words/s, in_qsize 8, out_qsize 0\n",
      "2021-02-26 22:00:08,149 : INFO : EPOCH 2 - PROGRESS: at 82.62% examples, 316554 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:00:09,169 : INFO : EPOCH 2 - PROGRESS: at 84.65% examples, 316789 words/s, in_qsize 7, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-26 22:00:10,178 : INFO : EPOCH 2 - PROGRESS: at 86.12% examples, 317109 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:00:11,181 : INFO : EPOCH 2 - PROGRESS: at 87.74% examples, 317299 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:00:12,186 : INFO : EPOCH 2 - PROGRESS: at 89.20% examples, 317494 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:00:13,188 : INFO : EPOCH 2 - PROGRESS: at 90.69% examples, 317745 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:00:14,194 : INFO : EPOCH 2 - PROGRESS: at 92.12% examples, 317898 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:00:15,199 : INFO : EPOCH 2 - PROGRESS: at 93.36% examples, 318066 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:00:16,214 : INFO : EPOCH 2 - PROGRESS: at 94.56% examples, 318198 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:00:17,233 : INFO : EPOCH 2 - PROGRESS: at 95.73% examples, 318434 words/s, in_qsize 8, out_qsize 0\n",
      "2021-02-26 22:00:18,253 : INFO : EPOCH 2 - PROGRESS: at 97.02% examples, 318766 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:00:19,257 : INFO : EPOCH 2 - PROGRESS: at 98.23% examples, 318950 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:00:20,292 : INFO : EPOCH 2 - PROGRESS: at 99.45% examples, 319174 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:00:20,659 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-02-26 22:00:20,662 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-02-26 22:00:20,676 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-02-26 22:00:20,734 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-02-26 22:00:20,736 : INFO : EPOCH - 2 : training on 27374377 raw words (21281943 effective words) took 66.6s, 319339 effective words/s\n",
      "2021-02-26 22:00:21,765 : INFO : EPOCH 3 - PROGRESS: at 2.22% examples, 306998 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:00:22,783 : INFO : EPOCH 3 - PROGRESS: at 4.18% examples, 321843 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:00:23,784 : INFO : EPOCH 3 - PROGRESS: at 6.40% examples, 328972 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:00:24,788 : INFO : EPOCH 3 - PROGRESS: at 8.34% examples, 331979 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:00:25,824 : INFO : EPOCH 3 - PROGRESS: at 9.96% examples, 331824 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:00:26,842 : INFO : EPOCH 3 - PROGRESS: at 11.74% examples, 332283 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:00:27,855 : INFO : EPOCH 3 - PROGRESS: at 13.20% examples, 332368 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:00:28,873 : INFO : EPOCH 3 - PROGRESS: at 14.94% examples, 332002 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:00:29,886 : INFO : EPOCH 3 - PROGRESS: at 16.61% examples, 333597 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:00:30,893 : INFO : EPOCH 3 - PROGRESS: at 18.36% examples, 334547 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:00:31,929 : INFO : EPOCH 3 - PROGRESS: at 20.11% examples, 332984 words/s, in_qsize 6, out_qsize 1\n",
      "2021-02-26 22:00:32,945 : INFO : EPOCH 3 - PROGRESS: at 21.81% examples, 332906 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:00:33,958 : INFO : EPOCH 3 - PROGRESS: at 23.80% examples, 334184 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:00:34,971 : INFO : EPOCH 3 - PROGRESS: at 25.72% examples, 333570 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:00:35,996 : INFO : EPOCH 3 - PROGRESS: at 27.56% examples, 332739 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:00:37,033 : INFO : EPOCH 3 - PROGRESS: at 29.12% examples, 329027 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:00:38,043 : INFO : EPOCH 3 - PROGRESS: at 30.32% examples, 323991 words/s, in_qsize 6, out_qsize 1\n",
      "2021-02-26 22:00:39,048 : INFO : EPOCH 3 - PROGRESS: at 31.32% examples, 319156 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:00:40,055 : INFO : EPOCH 3 - PROGRESS: at 32.23% examples, 314875 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:00:41,062 : INFO : EPOCH 3 - PROGRESS: at 33.14% examples, 310908 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:00:42,064 : INFO : EPOCH 3 - PROGRESS: at 34.18% examples, 307908 words/s, in_qsize 8, out_qsize 0\n",
      "2021-02-26 22:00:43,102 : INFO : EPOCH 3 - PROGRESS: at 35.13% examples, 304244 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:00:44,152 : INFO : EPOCH 3 - PROGRESS: at 36.07% examples, 301756 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:00:45,231 : INFO : EPOCH 3 - PROGRESS: at 37.20% examples, 299703 words/s, in_qsize 8, out_qsize 0\n",
      "2021-02-26 22:00:46,233 : INFO : EPOCH 3 - PROGRESS: at 38.21% examples, 298197 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:00:47,244 : INFO : EPOCH 3 - PROGRESS: at 39.28% examples, 297281 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:00:48,259 : INFO : EPOCH 3 - PROGRESS: at 40.37% examples, 296912 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:00:49,277 : INFO : EPOCH 3 - PROGRESS: at 41.55% examples, 297374 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:00:50,283 : INFO : EPOCH 3 - PROGRESS: at 42.79% examples, 298717 words/s, in_qsize 8, out_qsize 0\n",
      "2021-02-26 22:00:51,302 : INFO : EPOCH 3 - PROGRESS: at 44.12% examples, 299798 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:00:52,319 : INFO : EPOCH 3 - PROGRESS: at 45.41% examples, 301057 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:00:53,336 : INFO : EPOCH 3 - PROGRESS: at 46.67% examples, 301955 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:00:54,354 : INFO : EPOCH 3 - PROGRESS: at 48.12% examples, 302811 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:00:55,360 : INFO : EPOCH 3 - PROGRESS: at 49.60% examples, 303544 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:00:56,377 : INFO : EPOCH 3 - PROGRESS: at 51.10% examples, 304403 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:00:57,390 : INFO : EPOCH 3 - PROGRESS: at 52.74% examples, 304988 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:00:58,403 : INFO : EPOCH 3 - PROGRESS: at 54.66% examples, 305701 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:00:59,424 : INFO : EPOCH 3 - PROGRESS: at 56.94% examples, 306510 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:01:00,465 : INFO : EPOCH 3 - PROGRESS: at 59.22% examples, 307113 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:01:01,484 : INFO : EPOCH 3 - PROGRESS: at 61.47% examples, 307685 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:01:02,485 : INFO : EPOCH 3 - PROGRESS: at 63.06% examples, 308765 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:01:03,508 : INFO : EPOCH 3 - PROGRESS: at 64.39% examples, 309256 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:01:04,518 : INFO : EPOCH 3 - PROGRESS: at 66.01% examples, 310007 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:01:05,525 : INFO : EPOCH 3 - PROGRESS: at 67.34% examples, 310371 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:01:06,544 : INFO : EPOCH 3 - PROGRESS: at 68.76% examples, 310540 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:01:07,577 : INFO : EPOCH 3 - PROGRESS: at 70.02% examples, 310937 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:01:08,610 : INFO : EPOCH 3 - PROGRESS: at 71.43% examples, 311306 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:01:09,653 : INFO : EPOCH 3 - PROGRESS: at 72.86% examples, 311560 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:01:10,689 : INFO : EPOCH 3 - PROGRESS: at 74.21% examples, 311866 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:01:11,689 : INFO : EPOCH 3 - PROGRESS: at 75.54% examples, 312217 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:01:12,696 : INFO : EPOCH 3 - PROGRESS: at 76.84% examples, 311817 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:01:13,707 : INFO : EPOCH 3 - PROGRESS: at 78.04% examples, 309723 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:01:14,710 : INFO : EPOCH 3 - PROGRESS: at 79.89% examples, 309471 words/s, in_qsize 8, out_qsize 0\n",
      "2021-02-26 22:01:15,748 : INFO : EPOCH 3 - PROGRESS: at 81.48% examples, 308201 words/s, in_qsize 8, out_qsize 0\n",
      "2021-02-26 22:01:16,764 : INFO : EPOCH 3 - PROGRESS: at 82.99% examples, 306558 words/s, in_qsize 6, out_qsize 1\n",
      "2021-02-26 22:01:17,844 : INFO : EPOCH 3 - PROGRESS: at 84.51% examples, 305043 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:01:18,880 : INFO : EPOCH 3 - PROGRESS: at 85.61% examples, 303818 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:01:19,905 : INFO : EPOCH 3 - PROGRESS: at 86.97% examples, 303238 words/s, in_qsize 7, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-26 22:01:20,929 : INFO : EPOCH 3 - PROGRESS: at 88.29% examples, 302906 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:01:21,932 : INFO : EPOCH 3 - PROGRESS: at 89.58% examples, 302847 words/s, in_qsize 8, out_qsize 0\n",
      "2021-02-26 22:01:22,948 : INFO : EPOCH 3 - PROGRESS: at 90.93% examples, 302619 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:01:23,967 : INFO : EPOCH 3 - PROGRESS: at 92.06% examples, 301973 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:01:24,988 : INFO : EPOCH 3 - PROGRESS: at 93.21% examples, 301958 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:01:26,014 : INFO : EPOCH 3 - PROGRESS: at 94.34% examples, 301916 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:01:27,028 : INFO : EPOCH 3 - PROGRESS: at 95.15% examples, 300663 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:01:28,086 : INFO : EPOCH 3 - PROGRESS: at 95.97% examples, 299602 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:01:29,093 : INFO : EPOCH 3 - PROGRESS: at 96.94% examples, 298909 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:01:30,107 : INFO : EPOCH 3 - PROGRESS: at 97.90% examples, 298209 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:01:31,142 : INFO : EPOCH 3 - PROGRESS: at 98.82% examples, 297532 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:01:32,144 : INFO : EPOCH 3 - PROGRESS: at 99.72% examples, 297022 words/s, in_qsize 4, out_qsize 3\n",
      "2021-02-26 22:01:32,247 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-02-26 22:01:32,328 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-02-26 22:01:32,332 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-02-26 22:01:32,334 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-02-26 22:01:32,335 : INFO : EPOCH - 3 : training on 27374377 raw words (21283281 effective words) took 71.6s, 297286 effective words/s\n",
      "2021-02-26 22:01:33,401 : INFO : EPOCH 4 - PROGRESS: at 2.05% examples, 266792 words/s, in_qsize 8, out_qsize 0\n",
      "2021-02-26 22:01:34,461 : INFO : EPOCH 4 - PROGRESS: at 3.79% examples, 277085 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:01:35,470 : INFO : EPOCH 4 - PROGRESS: at 5.61% examples, 280216 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:01:36,472 : INFO : EPOCH 4 - PROGRESS: at 7.21% examples, 277007 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:01:37,490 : INFO : EPOCH 4 - PROGRESS: at 8.75% examples, 277001 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:01:38,492 : INFO : EPOCH 4 - PROGRESS: at 9.85% examples, 270387 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:01:39,529 : INFO : EPOCH 4 - PROGRESS: at 10.98% examples, 264675 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:01:40,559 : INFO : EPOCH 4 - PROGRESS: at 12.20% examples, 261483 words/s, in_qsize 8, out_qsize 1\n",
      "2021-02-26 22:01:41,601 : INFO : EPOCH 4 - PROGRESS: at 13.31% examples, 258545 words/s, in_qsize 8, out_qsize 0\n",
      "2021-02-26 22:01:42,627 : INFO : EPOCH 4 - PROGRESS: at 14.78% examples, 259489 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:01:43,643 : INFO : EPOCH 4 - PROGRESS: at 15.97% examples, 257772 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:01:44,678 : INFO : EPOCH 4 - PROGRESS: at 17.19% examples, 257187 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:01:45,737 : INFO : EPOCH 4 - PROGRESS: at 18.48% examples, 255206 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:01:46,777 : INFO : EPOCH 4 - PROGRESS: at 19.87% examples, 254833 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:01:47,785 : INFO : EPOCH 4 - PROGRESS: at 21.22% examples, 255572 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:01:48,793 : INFO : EPOCH 4 - PROGRESS: at 22.62% examples, 255816 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:01:49,803 : INFO : EPOCH 4 - PROGRESS: at 24.49% examples, 259071 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:01:50,806 : INFO : EPOCH 4 - PROGRESS: at 25.99% examples, 259515 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:01:51,854 : INFO : EPOCH 4 - PROGRESS: at 27.61% examples, 260488 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:01:52,876 : INFO : EPOCH 4 - PROGRESS: at 29.12% examples, 260990 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:01:53,879 : INFO : EPOCH 4 - PROGRESS: at 30.51% examples, 261985 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:01:54,903 : INFO : EPOCH 4 - PROGRESS: at 31.70% examples, 263347 words/s, in_qsize 8, out_qsize 0\n",
      "2021-02-26 22:01:55,910 : INFO : EPOCH 4 - PROGRESS: at 32.95% examples, 266081 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:01:56,911 : INFO : EPOCH 4 - PROGRESS: at 34.15% examples, 266852 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:01:57,924 : INFO : EPOCH 4 - PROGRESS: at 35.34% examples, 268274 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:01:58,926 : INFO : EPOCH 4 - PROGRESS: at 36.54% examples, 270270 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:01:59,933 : INFO : EPOCH 4 - PROGRESS: at 37.82% examples, 271833 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:02:00,939 : INFO : EPOCH 4 - PROGRESS: at 39.03% examples, 273030 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:02:02,000 : INFO : EPOCH 4 - PROGRESS: at 40.18% examples, 273893 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:02:03,004 : INFO : EPOCH 4 - PROGRESS: at 41.30% examples, 274440 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:02:04,006 : INFO : EPOCH 4 - PROGRESS: at 42.43% examples, 275483 words/s, in_qsize 6, out_qsize 1\n",
      "2021-02-26 22:02:05,010 : INFO : EPOCH 4 - PROGRESS: at 43.60% examples, 276637 words/s, in_qsize 8, out_qsize 0\n",
      "2021-02-26 22:02:06,016 : INFO : EPOCH 4 - PROGRESS: at 44.78% examples, 277263 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:02:07,048 : INFO : EPOCH 4 - PROGRESS: at 45.62% examples, 275388 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:02:08,053 : INFO : EPOCH 4 - PROGRESS: at 46.58% examples, 274903 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:02:09,061 : INFO : EPOCH 4 - PROGRESS: at 47.59% examples, 274011 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:02:10,076 : INFO : EPOCH 4 - PROGRESS: at 48.75% examples, 273348 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:02:11,145 : INFO : EPOCH 4 - PROGRESS: at 49.97% examples, 272741 words/s, in_qsize 6, out_qsize 1\n",
      "2021-02-26 22:02:12,169 : INFO : EPOCH 4 - PROGRESS: at 51.20% examples, 272905 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:02:13,205 : INFO : EPOCH 4 - PROGRESS: at 52.54% examples, 272540 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:02:14,236 : INFO : EPOCH 4 - PROGRESS: at 54.43% examples, 273856 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:02:15,270 : INFO : EPOCH 4 - PROGRESS: at 56.39% examples, 274335 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:02:16,276 : INFO : EPOCH 4 - PROGRESS: at 58.34% examples, 275013 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:02:17,292 : INFO : EPOCH 4 - PROGRESS: at 60.08% examples, 274568 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:02:18,299 : INFO : EPOCH 4 - PROGRESS: at 61.73% examples, 273887 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:02:19,318 : INFO : EPOCH 4 - PROGRESS: at 62.78% examples, 272858 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:02:20,348 : INFO : EPOCH 4 - PROGRESS: at 63.94% examples, 272910 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:02:21,364 : INFO : EPOCH 4 - PROGRESS: at 65.22% examples, 273816 words/s, in_qsize 8, out_qsize 0\n",
      "2021-02-26 22:02:22,394 : INFO : EPOCH 4 - PROGRESS: at 66.52% examples, 273842 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:02:23,405 : INFO : EPOCH 4 - PROGRESS: at 67.76% examples, 273832 words/s, in_qsize 8, out_qsize 0\n",
      "2021-02-26 22:02:24,420 : INFO : EPOCH 4 - PROGRESS: at 68.82% examples, 273389 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:02:25,425 : INFO : EPOCH 4 - PROGRESS: at 69.94% examples, 273871 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:02:26,447 : INFO : EPOCH 4 - PROGRESS: at 70.86% examples, 273108 words/s, in_qsize 8, out_qsize 0\n",
      "2021-02-26 22:02:27,451 : INFO : EPOCH 4 - PROGRESS: at 71.93% examples, 272598 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:02:28,460 : INFO : EPOCH 4 - PROGRESS: at 72.95% examples, 271933 words/s, in_qsize 8, out_qsize 0\n",
      "2021-02-26 22:02:29,489 : INFO : EPOCH 4 - PROGRESS: at 73.91% examples, 271347 words/s, in_qsize 8, out_qsize 0\n",
      "2021-02-26 22:02:30,506 : INFO : EPOCH 4 - PROGRESS: at 74.83% examples, 270560 words/s, in_qsize 7, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-26 22:02:31,555 : INFO : EPOCH 4 - PROGRESS: at 75.96% examples, 270187 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:02:32,582 : INFO : EPOCH 4 - PROGRESS: at 77.49% examples, 270657 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:02:33,592 : INFO : EPOCH 4 - PROGRESS: at 79.35% examples, 271176 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:02:34,605 : INFO : EPOCH 4 - PROGRESS: at 81.26% examples, 271651 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:02:35,609 : INFO : EPOCH 4 - PROGRESS: at 82.85% examples, 271087 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:02:36,626 : INFO : EPOCH 4 - PROGRESS: at 84.37% examples, 270472 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:02:37,674 : INFO : EPOCH 4 - PROGRESS: at 85.55% examples, 270123 words/s, in_qsize 6, out_qsize 1\n",
      "2021-02-26 22:02:38,687 : INFO : EPOCH 4 - PROGRESS: at 86.76% examples, 269717 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:02:39,692 : INFO : EPOCH 4 - PROGRESS: at 88.18% examples, 270345 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:02:40,747 : INFO : EPOCH 4 - PROGRESS: at 89.49% examples, 270561 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:02:41,773 : INFO : EPOCH 4 - PROGRESS: at 90.89% examples, 271010 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:02:42,779 : INFO : EPOCH 4 - PROGRESS: at 92.15% examples, 271373 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:02:43,807 : INFO : EPOCH 4 - PROGRESS: at 93.27% examples, 271658 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:02:44,843 : INFO : EPOCH 4 - PROGRESS: at 94.39% examples, 272016 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:02:45,876 : INFO : EPOCH 4 - PROGRESS: at 95.47% examples, 272281 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:02:46,938 : INFO : EPOCH 4 - PROGRESS: at 96.56% examples, 272545 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:02:47,953 : INFO : EPOCH 4 - PROGRESS: at 97.53% examples, 272249 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:02:48,974 : INFO : EPOCH 4 - PROGRESS: at 98.51% examples, 272333 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:02:49,988 : INFO : EPOCH 4 - PROGRESS: at 99.64% examples, 272834 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:02:50,208 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-02-26 22:02:50,241 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-02-26 22:02:50,256 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-02-26 22:02:50,263 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-02-26 22:02:50,264 : INFO : EPOCH - 4 : training on 27374377 raw words (21284152 effective words) took 77.9s, 273132 effective words/s\n",
      "2021-02-26 22:02:51,304 : INFO : EPOCH 5 - PROGRESS: at 2.05% examples, 273260 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:02:52,304 : INFO : EPOCH 5 - PROGRESS: at 3.83% examples, 292371 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:02:53,308 : INFO : EPOCH 5 - PROGRESS: at 5.74% examples, 295985 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:02:54,324 : INFO : EPOCH 5 - PROGRESS: at 7.49% examples, 295241 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:02:55,378 : INFO : EPOCH 5 - PROGRESS: at 9.13% examples, 293924 words/s, in_qsize 8, out_qsize 0\n",
      "2021-02-26 22:02:56,386 : INFO : EPOCH 5 - PROGRESS: at 10.47% examples, 294422 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:02:57,391 : INFO : EPOCH 5 - PROGRESS: at 12.02% examples, 294128 words/s, in_qsize 8, out_qsize 0\n",
      "2021-02-26 22:02:58,392 : INFO : EPOCH 5 - PROGRESS: at 13.26% examples, 292781 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:02:59,416 : INFO : EPOCH 5 - PROGRESS: at 14.87% examples, 293344 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:03:00,441 : INFO : EPOCH 5 - PROGRESS: at 16.31% examples, 293817 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:03:01,509 : INFO : EPOCH 5 - PROGRESS: at 17.74% examples, 291694 words/s, in_qsize 6, out_qsize 1\n",
      "2021-02-26 22:03:02,539 : INFO : EPOCH 5 - PROGRESS: at 19.39% examples, 292378 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:03:03,578 : INFO : EPOCH 5 - PROGRESS: at 20.77% examples, 289625 words/s, in_qsize 6, out_qsize 1\n",
      "2021-02-26 22:03:04,612 : INFO : EPOCH 5 - PROGRESS: at 22.38% examples, 290214 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:03:05,617 : INFO : EPOCH 5 - PROGRESS: at 23.80% examples, 287712 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:03:06,630 : INFO : EPOCH 5 - PROGRESS: at 25.37% examples, 286336 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:03:07,647 : INFO : EPOCH 5 - PROGRESS: at 26.83% examples, 284473 words/s, in_qsize 8, out_qsize 0\n",
      "2021-02-26 22:03:08,725 : INFO : EPOCH 5 - PROGRESS: at 28.41% examples, 283265 words/s, in_qsize 8, out_qsize 0\n",
      "2021-02-26 22:03:09,780 : INFO : EPOCH 5 - PROGRESS: at 29.83% examples, 282153 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:03:10,840 : INFO : EPOCH 5 - PROGRESS: at 30.96% examples, 279476 words/s, in_qsize 6, out_qsize 1\n",
      "2021-02-26 22:03:11,843 : INFO : EPOCH 5 - PROGRESS: at 31.81% examples, 276814 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:03:12,876 : INFO : EPOCH 5 - PROGRESS: at 32.77% examples, 275365 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:03:13,923 : INFO : EPOCH 5 - PROGRESS: at 33.86% examples, 273895 words/s, in_qsize 5, out_qsize 2\n",
      "2021-02-26 22:03:15,088 : INFO : EPOCH 5 - PROGRESS: at 34.83% examples, 270972 words/s, in_qsize 8, out_qsize 1\n",
      "2021-02-26 22:03:16,096 : INFO : EPOCH 5 - PROGRESS: at 35.61% examples, 268709 words/s, in_qsize 6, out_qsize 1\n",
      "2021-02-26 22:03:17,107 : INFO : EPOCH 5 - PROGRESS: at 36.68% examples, 268857 words/s, in_qsize 8, out_qsize 0\n",
      "2021-02-26 22:03:18,127 : INFO : EPOCH 5 - PROGRESS: at 37.58% examples, 267029 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:03:19,186 : INFO : EPOCH 5 - PROGRESS: at 38.71% examples, 267089 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:03:20,190 : INFO : EPOCH 5 - PROGRESS: at 39.53% examples, 265375 words/s, in_qsize 6, out_qsize 1\n",
      "2021-02-26 22:03:21,195 : INFO : EPOCH 5 - PROGRESS: at 40.30% examples, 263675 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:03:22,196 : INFO : EPOCH 5 - PROGRESS: at 41.41% examples, 264551 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:03:23,229 : INFO : EPOCH 5 - PROGRESS: at 42.17% examples, 262575 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:03:24,272 : INFO : EPOCH 5 - PROGRESS: at 43.11% examples, 262199 words/s, in_qsize 8, out_qsize 1\n",
      "2021-02-26 22:03:25,293 : INFO : EPOCH 5 - PROGRESS: at 44.12% examples, 261584 words/s, in_qsize 6, out_qsize 1\n",
      "2021-02-26 22:03:26,345 : INFO : EPOCH 5 - PROGRESS: at 45.15% examples, 261605 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:03:27,382 : INFO : EPOCH 5 - PROGRESS: at 46.32% examples, 262730 words/s, in_qsize 8, out_qsize 0\n",
      "2021-02-26 22:03:28,383 : INFO : EPOCH 5 - PROGRESS: at 47.59% examples, 264035 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:03:29,385 : INFO : EPOCH 5 - PROGRESS: at 49.05% examples, 265718 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:03:30,425 : INFO : EPOCH 5 - PROGRESS: at 50.29% examples, 265337 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:03:31,469 : INFO : EPOCH 5 - PROGRESS: at 51.47% examples, 265344 words/s, in_qsize 8, out_qsize 0\n",
      "2021-02-26 22:03:32,540 : INFO : EPOCH 5 - PROGRESS: at 52.96% examples, 265510 words/s, in_qsize 6, out_qsize 1\n",
      "2021-02-26 22:03:33,638 : INFO : EPOCH 5 - PROGRESS: at 54.57% examples, 265117 words/s, in_qsize 6, out_qsize 1\n",
      "2021-02-26 22:03:34,701 : INFO : EPOCH 5 - PROGRESS: at 56.16% examples, 264247 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:03:35,751 : INFO : EPOCH 5 - PROGRESS: at 57.82% examples, 263702 words/s, in_qsize 8, out_qsize 0\n",
      "2021-02-26 22:03:36,804 : INFO : EPOCH 5 - PROGRESS: at 59.49% examples, 263145 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:03:37,825 : INFO : EPOCH 5 - PROGRESS: at 61.07% examples, 262158 words/s, in_qsize 5, out_qsize 2\n",
      "2021-02-26 22:03:38,844 : INFO : EPOCH 5 - PROGRESS: at 62.17% examples, 261230 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:03:39,863 : INFO : EPOCH 5 - PROGRESS: at 63.24% examples, 260825 words/s, in_qsize 8, out_qsize 0\n",
      "2021-02-26 22:03:40,882 : INFO : EPOCH 5 - PROGRESS: at 64.27% examples, 260717 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:03:41,903 : INFO : EPOCH 5 - PROGRESS: at 65.39% examples, 260750 words/s, in_qsize 8, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-26 22:03:42,915 : INFO : EPOCH 5 - PROGRESS: at 66.69% examples, 261265 words/s, in_qsize 8, out_qsize 0\n",
      "2021-02-26 22:03:43,960 : INFO : EPOCH 5 - PROGRESS: at 68.02% examples, 261638 words/s, in_qsize 8, out_qsize 0\n",
      "2021-02-26 22:03:44,973 : INFO : EPOCH 5 - PROGRESS: at 69.06% examples, 261570 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:03:46,006 : INFO : EPOCH 5 - PROGRESS: at 70.15% examples, 261834 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:03:47,046 : INFO : EPOCH 5 - PROGRESS: at 71.08% examples, 261110 words/s, in_qsize 7, out_qsize 1\n",
      "2021-02-26 22:03:48,054 : INFO : EPOCH 5 - PROGRESS: at 72.27% examples, 261335 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:03:49,083 : INFO : EPOCH 5 - PROGRESS: at 73.27% examples, 260942 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:03:50,089 : INFO : EPOCH 5 - PROGRESS: at 74.15% examples, 260153 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:03:51,119 : INFO : EPOCH 5 - PROGRESS: at 75.08% examples, 259663 words/s, in_qsize 8, out_qsize 0\n",
      "2021-02-26 22:03:52,128 : INFO : EPOCH 5 - PROGRESS: at 76.36% examples, 260292 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:03:53,133 : INFO : EPOCH 5 - PROGRESS: at 77.99% examples, 260850 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:03:54,193 : INFO : EPOCH 5 - PROGRESS: at 79.80% examples, 261057 words/s, in_qsize 8, out_qsize 2\n",
      "2021-02-26 22:03:55,231 : INFO : EPOCH 5 - PROGRESS: at 81.70% examples, 261566 words/s, in_qsize 6, out_qsize 1\n",
      "2021-02-26 22:03:56,248 : INFO : EPOCH 5 - PROGRESS: at 83.93% examples, 262286 words/s, in_qsize 8, out_qsize 0\n",
      "2021-02-26 22:03:57,259 : INFO : EPOCH 5 - PROGRESS: at 85.35% examples, 262778 words/s, in_qsize 6, out_qsize 1\n",
      "2021-02-26 22:03:58,321 : INFO : EPOCH 5 - PROGRESS: at 86.70% examples, 262754 words/s, in_qsize 5, out_qsize 2\n",
      "2021-02-26 22:03:59,384 : INFO : EPOCH 5 - PROGRESS: at 88.14% examples, 263366 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:04:00,463 : INFO : EPOCH 5 - PROGRESS: at 89.49% examples, 263701 words/s, in_qsize 6, out_qsize 1\n",
      "2021-02-26 22:04:01,479 : INFO : EPOCH 5 - PROGRESS: at 90.89% examples, 264275 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:04:02,527 : INFO : EPOCH 5 - PROGRESS: at 92.12% examples, 264462 words/s, in_qsize 8, out_qsize 3\n",
      "2021-02-26 22:04:03,566 : INFO : EPOCH 5 - PROGRESS: at 93.28% examples, 264905 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:04:04,569 : INFO : EPOCH 5 - PROGRESS: at 94.32% examples, 265149 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:04:05,605 : INFO : EPOCH 5 - PROGRESS: at 95.39% examples, 265493 words/s, in_qsize 8, out_qsize 1\n",
      "2021-02-26 22:04:06,614 : INFO : EPOCH 5 - PROGRESS: at 96.36% examples, 265623 words/s, in_qsize 5, out_qsize 2\n",
      "2021-02-26 22:04:07,638 : INFO : EPOCH 5 - PROGRESS: at 97.47% examples, 265886 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:04:08,646 : INFO : EPOCH 5 - PROGRESS: at 98.36% examples, 265803 words/s, in_qsize 6, out_qsize 1\n",
      "2021-02-26 22:04:09,703 : INFO : EPOCH 5 - PROGRESS: at 99.42% examples, 265938 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:04:10,185 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-02-26 22:04:10,188 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-02-26 22:04:10,224 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-02-26 22:04:10,226 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-02-26 22:04:10,226 : INFO : EPOCH - 5 : training on 27374377 raw words (21285476 effective words) took 80.0s, 266204 effective words/s\n",
      "2021-02-26 22:04:10,228 : INFO : training on a 136871885 raw words (106416042 effective words) took 360.8s, 294921 effective words/s\n"
     ]
    }
   ],
   "source": [
    "vectors9 = gensim.models.Word2Vec(tokenized_text1, size= 10, min_count=1, sg=1, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-26 22:04:39,225 : WARNING : Effective 'alpha' higher than previous training cycles\n",
      "2021-02-26 22:04:39,229 : INFO : training model with 4 workers on 257022 vocabulary and 10 features, using sg=1 hs=0 sample=0.001 negative=5 window=5\n",
      "2021-02-26 22:04:40,279 : INFO : EPOCH 1 - PROGRESS: at 2.55% examples, 358649 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:04:41,286 : INFO : EPOCH 1 - PROGRESS: at 4.38% examples, 334630 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:04:42,296 : INFO : EPOCH 1 - PROGRESS: at 6.53% examples, 334164 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:04:43,362 : INFO : EPOCH 1 - PROGRESS: at 8.34% examples, 325247 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:04:44,393 : INFO : EPOCH 1 - PROGRESS: at 9.82% examples, 320936 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:04:45,427 : INFO : EPOCH 1 - PROGRESS: at 11.49% examples, 318451 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:04:46,453 : INFO : EPOCH 1 - PROGRESS: at 12.82% examples, 316871 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:04:47,555 : INFO : EPOCH 1 - PROGRESS: at 14.35% examples, 311529 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:04:48,597 : INFO : EPOCH 1 - PROGRESS: at 15.75% examples, 307102 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:04:49,632 : INFO : EPOCH 1 - PROGRESS: at 17.07% examples, 302976 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:04:50,647 : INFO : EPOCH 1 - PROGRESS: at 18.36% examples, 297559 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:04:51,658 : INFO : EPOCH 1 - PROGRESS: at 20.00% examples, 297998 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:04:52,670 : INFO : EPOCH 1 - PROGRESS: at 21.39% examples, 296072 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:04:53,679 : INFO : EPOCH 1 - PROGRESS: at 22.94% examples, 295612 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:04:54,682 : INFO : EPOCH 1 - PROGRESS: at 24.02% examples, 288864 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:04:55,691 : INFO : EPOCH 1 - PROGRESS: at 25.95% examples, 290692 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:04:56,735 : INFO : EPOCH 1 - PROGRESS: at 27.84% examples, 292623 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:04:57,795 : INFO : EPOCH 1 - PROGRESS: at 29.28% examples, 290802 words/s, in_qsize 6, out_qsize 1\n",
      "2021-02-26 22:04:58,805 : INFO : EPOCH 1 - PROGRESS: at 30.64% examples, 289856 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:04:59,818 : INFO : EPOCH 1 - PROGRESS: at 31.84% examples, 290508 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:05:00,903 : INFO : EPOCH 1 - PROGRESS: at 33.01% examples, 290102 words/s, in_qsize 8, out_qsize 2\n",
      "2021-02-26 22:05:01,970 : INFO : EPOCH 1 - PROGRESS: at 34.18% examples, 288692 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:05:02,996 : INFO : EPOCH 1 - PROGRESS: at 35.25% examples, 287839 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:05:04,047 : INFO : EPOCH 1 - PROGRESS: at 36.38% examples, 288043 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:05:05,087 : INFO : EPOCH 1 - PROGRESS: at 37.52% examples, 287119 words/s, in_qsize 8, out_qsize 0\n",
      "2021-02-26 22:05:06,152 : INFO : EPOCH 1 - PROGRESS: at 38.52% examples, 285149 words/s, in_qsize 8, out_qsize 2\n",
      "2021-02-26 22:05:07,245 : INFO : EPOCH 1 - PROGRESS: at 39.46% examples, 282882 words/s, in_qsize 4, out_qsize 3\n",
      "2021-02-26 22:05:08,289 : INFO : EPOCH 1 - PROGRESS: at 40.49% examples, 282205 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:05:09,312 : INFO : EPOCH 1 - PROGRESS: at 41.57% examples, 282325 words/s, in_qsize 8, out_qsize 0\n",
      "2021-02-26 22:05:10,334 : INFO : EPOCH 1 - PROGRESS: at 42.68% examples, 282703 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:05:11,359 : INFO : EPOCH 1 - PROGRESS: at 43.87% examples, 283228 words/s, in_qsize 8, out_qsize 0\n",
      "2021-02-26 22:05:12,368 : INFO : EPOCH 1 - PROGRESS: at 45.17% examples, 285016 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:05:13,391 : INFO : EPOCH 1 - PROGRESS: at 46.47% examples, 286521 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:05:14,393 : INFO : EPOCH 1 - PROGRESS: at 47.82% examples, 287701 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:05:15,436 : INFO : EPOCH 1 - PROGRESS: at 49.18% examples, 287896 words/s, in_qsize 6, out_qsize 1\n",
      "2021-02-26 22:05:16,470 : INFO : EPOCH 1 - PROGRESS: at 50.66% examples, 288572 words/s, in_qsize 6, out_qsize 1\n",
      "2021-02-26 22:05:17,480 : INFO : EPOCH 1 - PROGRESS: at 52.12% examples, 289202 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:05:18,480 : INFO : EPOCH 1 - PROGRESS: at 53.99% examples, 290402 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:05:19,500 : INFO : EPOCH 1 - PROGRESS: at 55.93% examples, 290778 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:05:20,502 : INFO : EPOCH 1 - PROGRESS: at 58.03% examples, 291500 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:05:21,510 : INFO : EPOCH 1 - PROGRESS: at 59.98% examples, 291598 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:05:22,526 : INFO : EPOCH 1 - PROGRESS: at 61.77% examples, 290944 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:05:23,551 : INFO : EPOCH 1 - PROGRESS: at 63.18% examples, 291500 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:05:24,579 : INFO : EPOCH 1 - PROGRESS: at 64.51% examples, 292326 words/s, in_qsize 6, out_qsize 1\n",
      "2021-02-26 22:05:25,598 : INFO : EPOCH 1 - PROGRESS: at 66.17% examples, 293495 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:05:26,604 : INFO : EPOCH 1 - PROGRESS: at 67.68% examples, 294855 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:05:27,697 : INFO : EPOCH 1 - PROGRESS: at 69.09% examples, 295377 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:05:28,738 : INFO : EPOCH 1 - PROGRESS: at 70.21% examples, 295070 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:05:29,788 : INFO : EPOCH 1 - PROGRESS: at 71.61% examples, 295653 words/s, in_qsize 8, out_qsize 0\n",
      "2021-02-26 22:05:30,858 : INFO : EPOCH 1 - PROGRESS: at 72.92% examples, 295461 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:05:31,882 : INFO : EPOCH 1 - PROGRESS: at 74.26% examples, 296130 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:05:32,912 : INFO : EPOCH 1 - PROGRESS: at 75.54% examples, 296318 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:05:33,915 : INFO : EPOCH 1 - PROGRESS: at 77.15% examples, 297205 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:05:34,924 : INFO : EPOCH 1 - PROGRESS: at 79.19% examples, 297833 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:05:35,937 : INFO : EPOCH 1 - PROGRESS: at 81.30% examples, 298423 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:05:36,937 : INFO : EPOCH 1 - PROGRESS: at 83.70% examples, 299200 words/s, in_qsize 8, out_qsize 0\n",
      "2021-02-26 22:05:37,989 : INFO : EPOCH 1 - PROGRESS: at 85.35% examples, 299567 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:05:38,989 : INFO : EPOCH 1 - PROGRESS: at 86.87% examples, 299839 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:05:40,001 : INFO : EPOCH 1 - PROGRESS: at 88.22% examples, 299755 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:05:41,053 : INFO : EPOCH 1 - PROGRESS: at 89.62% examples, 299883 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:05:42,075 : INFO : EPOCH 1 - PROGRESS: at 91.06% examples, 300039 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:05:43,083 : INFO : EPOCH 1 - PROGRESS: at 92.37% examples, 300217 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:05:44,108 : INFO : EPOCH 1 - PROGRESS: at 93.44% examples, 299972 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:05:45,114 : INFO : EPOCH 1 - PROGRESS: at 94.58% examples, 300173 words/s, in_qsize 8, out_qsize 0\n",
      "2021-02-26 22:05:46,156 : INFO : EPOCH 1 - PROGRESS: at 95.63% examples, 299984 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:05:47,159 : INFO : EPOCH 1 - PROGRESS: at 96.86% examples, 300437 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:05:48,162 : INFO : EPOCH 1 - PROGRESS: at 97.90% examples, 300093 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:05:49,172 : INFO : EPOCH 1 - PROGRESS: at 98.91% examples, 299927 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:05:50,176 : INFO : EPOCH 1 - PROGRESS: at 99.87% examples, 299480 words/s, in_qsize 5, out_qsize 0\n",
      "2021-02-26 22:05:50,232 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-02-26 22:05:50,254 : INFO : worker thread finished; awaiting finish of 2 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-26 22:05:50,263 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-02-26 22:05:50,290 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-02-26 22:05:50,291 : INFO : EPOCH - 1 : training on 27374377 raw words (21282478 effective words) took 71.1s, 299516 effective words/s\n",
      "2021-02-26 22:05:51,307 : INFO : EPOCH 2 - PROGRESS: at 2.10% examples, 287341 words/s, in_qsize 6, out_qsize 1\n",
      "2021-02-26 22:05:52,371 : INFO : EPOCH 2 - PROGRESS: at 3.79% examples, 283194 words/s, in_qsize 8, out_qsize 0\n",
      "2021-02-26 22:05:53,386 : INFO : EPOCH 2 - PROGRESS: at 5.57% examples, 281405 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:05:54,392 : INFO : EPOCH 2 - PROGRESS: at 7.58% examples, 296127 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:05:55,400 : INFO : EPOCH 2 - PROGRESS: at 9.13% examples, 294371 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:05:56,406 : INFO : EPOCH 2 - PROGRESS: at 10.63% examples, 300044 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:05:57,409 : INFO : EPOCH 2 - PROGRESS: at 12.17% examples, 300931 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:05:58,440 : INFO : EPOCH 2 - PROGRESS: at 13.63% examples, 302365 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:05:59,447 : INFO : EPOCH 2 - PROGRESS: at 15.26% examples, 301683 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:06:00,451 : INFO : EPOCH 2 - PROGRESS: at 16.80% examples, 304887 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:06:01,472 : INFO : EPOCH 2 - PROGRESS: at 18.54% examples, 307213 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:06:02,516 : INFO : EPOCH 2 - PROGRESS: at 20.36% examples, 309168 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:06:03,545 : INFO : EPOCH 2 - PROGRESS: at 22.05% examples, 310638 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:06:04,580 : INFO : EPOCH 2 - PROGRESS: at 23.98% examples, 311823 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:06:05,599 : INFO : EPOCH 2 - PROGRESS: at 25.81% examples, 311102 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:06:06,611 : INFO : EPOCH 2 - PROGRESS: at 27.56% examples, 311042 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:06:07,626 : INFO : EPOCH 2 - PROGRESS: at 29.28% examples, 311434 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:06:08,635 : INFO : EPOCH 2 - PROGRESS: at 30.64% examples, 309302 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:06:09,670 : INFO : EPOCH 2 - PROGRESS: at 31.94% examples, 309801 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:06:10,683 : INFO : EPOCH 2 - PROGRESS: at 33.27% examples, 311330 words/s, in_qsize 8, out_qsize 1\n",
      "2021-02-26 22:06:11,731 : INFO : EPOCH 2 - PROGRESS: at 34.77% examples, 312992 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:06:12,772 : INFO : EPOCH 2 - PROGRESS: at 36.02% examples, 313544 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:06:13,775 : INFO : EPOCH 2 - PROGRESS: at 37.23% examples, 312841 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:06:14,784 : INFO : EPOCH 2 - PROGRESS: at 38.30% examples, 311243 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:06:15,829 : INFO : EPOCH 2 - PROGRESS: at 39.53% examples, 310939 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:06:16,893 : INFO : EPOCH 2 - PROGRESS: at 40.68% examples, 309995 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:06:17,898 : INFO : EPOCH 2 - PROGRESS: at 41.74% examples, 309292 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:06:18,899 : INFO : EPOCH 2 - PROGRESS: at 42.84% examples, 308975 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:06:19,912 : INFO : EPOCH 2 - PROGRESS: at 44.15% examples, 309555 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:06:20,952 : INFO : EPOCH 2 - PROGRESS: at 45.20% examples, 308279 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:06:21,960 : INFO : EPOCH 2 - PROGRESS: at 46.23% examples, 307151 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:06:22,979 : INFO : EPOCH 2 - PROGRESS: at 47.32% examples, 305957 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:06:23,995 : INFO : EPOCH 2 - PROGRESS: at 48.72% examples, 305833 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:06:25,004 : INFO : EPOCH 2 - PROGRESS: at 49.87% examples, 304212 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:06:26,042 : INFO : EPOCH 2 - PROGRESS: at 51.10% examples, 303367 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:06:27,050 : INFO : EPOCH 2 - PROGRESS: at 52.78% examples, 304233 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:06:28,060 : INFO : EPOCH 2 - PROGRESS: at 54.80% examples, 305381 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:06:29,061 : INFO : EPOCH 2 - PROGRESS: at 57.07% examples, 306161 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:06:30,064 : INFO : EPOCH 2 - PROGRESS: at 59.01% examples, 305910 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:06:31,075 : INFO : EPOCH 2 - PROGRESS: at 61.11% examples, 305822 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:06:32,081 : INFO : EPOCH 2 - PROGRESS: at 62.45% examples, 305070 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:06:33,113 : INFO : EPOCH 2 - PROGRESS: at 63.61% examples, 304182 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:06:34,129 : INFO : EPOCH 2 - PROGRESS: at 64.76% examples, 303772 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:06:35,146 : INFO : EPOCH 2 - PROGRESS: at 66.27% examples, 304059 words/s, in_qsize 8, out_qsize 0\n",
      "2021-02-26 22:06:36,165 : INFO : EPOCH 2 - PROGRESS: at 67.58% examples, 304138 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:06:37,171 : INFO : EPOCH 2 - PROGRESS: at 68.85% examples, 303870 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:06:38,202 : INFO : EPOCH 2 - PROGRESS: at 69.83% examples, 302804 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:06:39,213 : INFO : EPOCH 2 - PROGRESS: at 71.05% examples, 302840 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:06:40,220 : INFO : EPOCH 2 - PROGRESS: at 72.23% examples, 302268 words/s, in_qsize 8, out_qsize 0\n",
      "2021-02-26 22:06:41,259 : INFO : EPOCH 2 - PROGRESS: at 73.30% examples, 301223 words/s, in_qsize 8, out_qsize 1\n",
      "2021-02-26 22:06:42,268 : INFO : EPOCH 2 - PROGRESS: at 74.40% examples, 300686 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:06:43,299 : INFO : EPOCH 2 - PROGRESS: at 75.83% examples, 301228 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:06:44,368 : INFO : EPOCH 2 - PROGRESS: at 77.16% examples, 300516 words/s, in_qsize 6, out_qsize 1\n",
      "2021-02-26 22:06:45,389 : INFO : EPOCH 2 - PROGRESS: at 78.98% examples, 300465 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:06:46,426 : INFO : EPOCH 2 - PROGRESS: at 81.21% examples, 301167 words/s, in_qsize 6, out_qsize 1\n",
      "2021-02-26 22:06:47,455 : INFO : EPOCH 2 - PROGRESS: at 83.56% examples, 301617 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:06:48,477 : INFO : EPOCH 2 - PROGRESS: at 84.90% examples, 300782 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:06:49,484 : INFO : EPOCH 2 - PROGRESS: at 86.24% examples, 300729 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:06:50,485 : INFO : EPOCH 2 - PROGRESS: at 87.45% examples, 299925 words/s, in_qsize 8, out_qsize 3\n",
      "2021-02-26 22:06:51,558 : INFO : EPOCH 2 - PROGRESS: at 88.87% examples, 299672 words/s, in_qsize 6, out_qsize 1\n",
      "2021-02-26 22:06:52,608 : INFO : EPOCH 2 - PROGRESS: at 90.30% examples, 300091 words/s, in_qsize 6, out_qsize 1\n",
      "2021-02-26 22:06:53,629 : INFO : EPOCH 2 - PROGRESS: at 91.88% examples, 300578 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:06:54,634 : INFO : EPOCH 2 - PROGRESS: at 93.16% examples, 301252 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:06:55,636 : INFO : EPOCH 2 - PROGRESS: at 94.45% examples, 302036 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:06:56,643 : INFO : EPOCH 2 - PROGRESS: at 95.63% examples, 302559 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:06:57,650 : INFO : EPOCH 2 - PROGRESS: at 96.86% examples, 302954 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:06:58,654 : INFO : EPOCH 2 - PROGRESS: at 98.13% examples, 303582 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:06:59,680 : INFO : EPOCH 2 - PROGRESS: at 99.25% examples, 303730 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:07:00,292 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-02-26 22:07:00,328 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-02-26 22:07:00,336 : INFO : worker thread finished; awaiting finish of 1 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-26 22:07:00,352 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-02-26 22:07:00,353 : INFO : EPOCH - 2 : training on 27374377 raw words (21281193 effective words) took 70.1s, 303760 effective words/s\n",
      "2021-02-26 22:07:01,391 : INFO : EPOCH 3 - PROGRESS: at 2.26% examples, 310603 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:07:02,393 : INFO : EPOCH 3 - PROGRESS: at 4.05% examples, 310919 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:07:03,395 : INFO : EPOCH 3 - PROGRESS: at 6.26% examples, 321531 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:07:04,406 : INFO : EPOCH 3 - PROGRESS: at 7.99% examples, 316419 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:07:05,408 : INFO : EPOCH 3 - PROGRESS: at 9.61% examples, 318558 words/s, in_qsize 8, out_qsize 0\n",
      "2021-02-26 22:07:06,422 : INFO : EPOCH 3 - PROGRESS: at 10.98% examples, 313642 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:07:07,446 : INFO : EPOCH 3 - PROGRESS: at 12.41% examples, 310638 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:07:08,448 : INFO : EPOCH 3 - PROGRESS: at 13.93% examples, 312681 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:07:09,448 : INFO : EPOCH 3 - PROGRESS: at 15.80% examples, 317066 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:07:10,454 : INFO : EPOCH 3 - PROGRESS: at 17.53% examples, 321019 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:07:11,470 : INFO : EPOCH 3 - PROGRESS: at 19.23% examples, 320115 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:07:12,520 : INFO : EPOCH 3 - PROGRESS: at 20.95% examples, 320123 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:07:13,596 : INFO : EPOCH 3 - PROGRESS: at 22.42% examples, 315046 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:07:14,596 : INFO : EPOCH 3 - PROGRESS: at 23.98% examples, 312856 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:07:15,599 : INFO : EPOCH 3 - PROGRESS: at 25.86% examples, 312908 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:07:16,600 : INFO : EPOCH 3 - PROGRESS: at 27.51% examples, 311968 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:07:17,602 : INFO : EPOCH 3 - PROGRESS: at 29.25% examples, 312561 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:07:18,629 : INFO : EPOCH 3 - PROGRESS: at 30.67% examples, 310888 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:07:19,634 : INFO : EPOCH 3 - PROGRESS: at 31.84% examples, 310200 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:07:20,639 : INFO : EPOCH 3 - PROGRESS: at 33.16% examples, 311813 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:07:21,647 : INFO : EPOCH 3 - PROGRESS: at 34.62% examples, 313348 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:07:22,654 : INFO : EPOCH 3 - PROGRESS: at 35.93% examples, 315041 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:07:23,665 : INFO : EPOCH 3 - PROGRESS: at 37.34% examples, 316466 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:07:24,690 : INFO : EPOCH 3 - PROGRESS: at 38.40% examples, 314193 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:07:25,727 : INFO : EPOCH 3 - PROGRESS: at 39.46% examples, 312328 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:07:26,746 : INFO : EPOCH 3 - PROGRESS: at 40.56% examples, 311287 words/s, in_qsize 6, out_qsize 1\n",
      "2021-02-26 22:07:27,749 : INFO : EPOCH 3 - PROGRESS: at 41.63% examples, 310557 words/s, in_qsize 6, out_qsize 1\n",
      "2021-02-26 22:07:28,764 : INFO : EPOCH 3 - PROGRESS: at 42.70% examples, 309768 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:07:29,768 : INFO : EPOCH 3 - PROGRESS: at 43.93% examples, 309889 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:07:30,796 : INFO : EPOCH 3 - PROGRESS: at 45.00% examples, 308746 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:07:31,813 : INFO : EPOCH 3 - PROGRESS: at 46.35% examples, 310177 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:07:32,821 : INFO : EPOCH 3 - PROGRESS: at 47.86% examples, 311815 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:07:33,847 : INFO : EPOCH 3 - PROGRESS: at 49.34% examples, 312347 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:07:34,895 : INFO : EPOCH 3 - PROGRESS: at 50.62% examples, 310893 words/s, in_qsize 8, out_qsize 0\n",
      "2021-02-26 22:07:35,923 : INFO : EPOCH 3 - PROGRESS: at 51.89% examples, 309713 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:07:36,969 : INFO : EPOCH 3 - PROGRESS: at 53.51% examples, 309225 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:07:38,010 : INFO : EPOCH 3 - PROGRESS: at 55.17% examples, 307941 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:07:39,013 : INFO : EPOCH 3 - PROGRESS: at 57.53% examples, 309044 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:07:40,035 : INFO : EPOCH 3 - PROGRESS: at 59.45% examples, 308380 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:07:41,051 : INFO : EPOCH 3 - PROGRESS: at 61.47% examples, 308011 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:07:42,065 : INFO : EPOCH 3 - PROGRESS: at 62.81% examples, 307517 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:07:43,074 : INFO : EPOCH 3 - PROGRESS: at 64.10% examples, 307611 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:07:44,079 : INFO : EPOCH 3 - PROGRESS: at 65.42% examples, 308068 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:07:45,086 : INFO : EPOCH 3 - PROGRESS: at 66.67% examples, 307296 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:07:46,116 : INFO : EPOCH 3 - PROGRESS: at 68.19% examples, 307789 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:07:47,143 : INFO : EPOCH 3 - PROGRESS: at 69.25% examples, 306950 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:07:48,147 : INFO : EPOCH 3 - PROGRESS: at 70.61% examples, 307904 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:07:49,173 : INFO : EPOCH 3 - PROGRESS: at 71.80% examples, 307122 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:07:50,212 : INFO : EPOCH 3 - PROGRESS: at 73.03% examples, 306560 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:07:51,228 : INFO : EPOCH 3 - PROGRESS: at 74.21% examples, 306181 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:07:52,241 : INFO : EPOCH 3 - PROGRESS: at 75.58% examples, 306716 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:07:53,248 : INFO : EPOCH 3 - PROGRESS: at 76.61% examples, 305564 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:07:54,274 : INFO : EPOCH 3 - PROGRESS: at 78.60% examples, 305937 words/s, in_qsize 8, out_qsize 0\n",
      "2021-02-26 22:07:55,280 : INFO : EPOCH 3 - PROGRESS: at 80.40% examples, 305475 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:07:56,284 : INFO : EPOCH 3 - PROGRESS: at 82.18% examples, 305017 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:07:57,298 : INFO : EPOCH 3 - PROGRESS: at 84.33% examples, 305228 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:07:58,306 : INFO : EPOCH 3 - PROGRESS: at 85.76% examples, 305481 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:07:59,315 : INFO : EPOCH 3 - PROGRESS: at 87.19% examples, 305323 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:08:00,325 : INFO : EPOCH 3 - PROGRESS: at 88.56% examples, 304907 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:08:01,383 : INFO : EPOCH 3 - PROGRESS: at 89.75% examples, 304285 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:08:02,416 : INFO : EPOCH 3 - PROGRESS: at 91.03% examples, 303707 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:08:03,426 : INFO : EPOCH 3 - PROGRESS: at 92.21% examples, 303328 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:08:04,428 : INFO : EPOCH 3 - PROGRESS: at 93.24% examples, 302904 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:08:05,442 : INFO : EPOCH 3 - PROGRESS: at 94.37% examples, 302905 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:08:06,465 : INFO : EPOCH 3 - PROGRESS: at 95.58% examples, 303464 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:08:07,485 : INFO : EPOCH 3 - PROGRESS: at 96.80% examples, 303784 words/s, in_qsize 8, out_qsize 0\n",
      "2021-02-26 22:08:08,499 : INFO : EPOCH 3 - PROGRESS: at 97.98% examples, 303901 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:08:09,513 : INFO : EPOCH 3 - PROGRESS: at 99.01% examples, 303770 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:08:10,320 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-02-26 22:08:10,351 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-02-26 22:08:10,372 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-02-26 22:08:10,391 : INFO : worker thread finished; awaiting finish of 0 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-26 22:08:10,393 : INFO : EPOCH - 3 : training on 27374377 raw words (21283801 effective words) took 70.0s, 303896 effective words/s\n",
      "2021-02-26 22:08:11,409 : INFO : EPOCH 4 - PROGRESS: at 2.05% examples, 279551 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:08:12,415 : INFO : EPOCH 4 - PROGRESS: at 3.83% examples, 294681 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:08:13,419 : INFO : EPOCH 4 - PROGRESS: at 5.88% examples, 305061 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:08:14,441 : INFO : EPOCH 4 - PROGRESS: at 7.94% examples, 314716 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:08:15,447 : INFO : EPOCH 4 - PROGRESS: at 9.68% examples, 321438 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:08:16,485 : INFO : EPOCH 4 - PROGRESS: at 11.49% examples, 323747 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:08:17,491 : INFO : EPOCH 4 - PROGRESS: at 12.96% examples, 326587 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:08:18,498 : INFO : EPOCH 4 - PROGRESS: at 14.69% examples, 327392 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:08:19,502 : INFO : EPOCH 4 - PROGRESS: at 16.34% examples, 329066 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:08:20,530 : INFO : EPOCH 4 - PROGRESS: at 17.99% examples, 328030 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:08:21,536 : INFO : EPOCH 4 - PROGRESS: at 19.79% examples, 328782 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:08:22,541 : INFO : EPOCH 4 - PROGRESS: at 21.63% examples, 331244 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:08:23,580 : INFO : EPOCH 4 - PROGRESS: at 23.57% examples, 331400 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:08:24,633 : INFO : EPOCH 4 - PROGRESS: at 25.68% examples, 332759 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:08:25,653 : INFO : EPOCH 4 - PROGRESS: at 27.71% examples, 334091 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:08:26,663 : INFO : EPOCH 4 - PROGRESS: at 29.35% examples, 332693 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:08:27,666 : INFO : EPOCH 4 - PROGRESS: at 30.98% examples, 333289 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:08:28,667 : INFO : EPOCH 4 - PROGRESS: at 32.29% examples, 333519 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:08:29,692 : INFO : EPOCH 4 - PROGRESS: at 33.63% examples, 332872 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:08:30,708 : INFO : EPOCH 4 - PROGRESS: at 35.05% examples, 333648 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:08:31,720 : INFO : EPOCH 4 - PROGRESS: at 36.35% examples, 334738 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:08:32,724 : INFO : EPOCH 4 - PROGRESS: at 37.66% examples, 334103 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:08:33,741 : INFO : EPOCH 4 - PROGRESS: at 39.09% examples, 335040 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:08:34,752 : INFO : EPOCH 4 - PROGRESS: at 40.36% examples, 335300 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:08:35,792 : INFO : EPOCH 4 - PROGRESS: at 41.71% examples, 335807 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:08:36,836 : INFO : EPOCH 4 - PROGRESS: at 42.73% examples, 333035 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:08:37,839 : INFO : EPOCH 4 - PROGRESS: at 43.87% examples, 331469 words/s, in_qsize 8, out_qsize 0\n",
      "2021-02-26 22:08:38,855 : INFO : EPOCH 4 - PROGRESS: at 44.86% examples, 328818 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:08:39,869 : INFO : EPOCH 4 - PROGRESS: at 45.90% examples, 326829 words/s, in_qsize 8, out_qsize 0\n",
      "2021-02-26 22:08:40,920 : INFO : EPOCH 4 - PROGRESS: at 46.87% examples, 323805 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:08:41,952 : INFO : EPOCH 4 - PROGRESS: at 48.03% examples, 321919 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:08:42,983 : INFO : EPOCH 4 - PROGRESS: at 49.55% examples, 322100 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:08:44,022 : INFO : EPOCH 4 - PROGRESS: at 50.92% examples, 321317 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:08:45,063 : INFO : EPOCH 4 - PROGRESS: at 52.21% examples, 319663 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:08:46,109 : INFO : EPOCH 4 - PROGRESS: at 53.81% examples, 318232 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:08:47,157 : INFO : EPOCH 4 - PROGRESS: at 55.88% examples, 318247 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:08:48,162 : INFO : EPOCH 4 - PROGRESS: at 58.07% examples, 318694 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:08:49,170 : INFO : EPOCH 4 - PROGRESS: at 60.33% examples, 319082 words/s, in_qsize 8, out_qsize 0\n",
      "2021-02-26 22:08:50,184 : INFO : EPOCH 4 - PROGRESS: at 62.26% examples, 319426 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:08:51,211 : INFO : EPOCH 4 - PROGRESS: at 63.58% examples, 318916 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:08:52,241 : INFO : EPOCH 4 - PROGRESS: at 64.61% examples, 317282 words/s, in_qsize 8, out_qsize 1\n",
      "2021-02-26 22:08:53,333 : INFO : EPOCH 4 - PROGRESS: at 66.08% examples, 316360 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:08:54,357 : INFO : EPOCH 4 - PROGRESS: at 67.34% examples, 316117 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:08:55,398 : INFO : EPOCH 4 - PROGRESS: at 68.57% examples, 314966 words/s, in_qsize 6, out_qsize 1\n",
      "2021-02-26 22:08:56,431 : INFO : EPOCH 4 - PROGRESS: at 69.64% examples, 313939 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:08:57,450 : INFO : EPOCH 4 - PROGRESS: at 70.70% examples, 313177 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:08:58,458 : INFO : EPOCH 4 - PROGRESS: at 71.80% examples, 311912 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:08:59,459 : INFO : EPOCH 4 - PROGRESS: at 73.00% examples, 311323 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:09:00,587 : INFO : EPOCH 4 - PROGRESS: at 74.23% examples, 310450 words/s, in_qsize 6, out_qsize 1\n",
      "2021-02-26 22:09:01,596 : INFO : EPOCH 4 - PROGRESS: at 75.47% examples, 310330 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:09:02,597 : INFO : EPOCH 4 - PROGRESS: at 76.84% examples, 310296 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:09:03,598 : INFO : EPOCH 4 - PROGRESS: at 78.59% examples, 310015 words/s, in_qsize 6, out_qsize 1\n",
      "2021-02-26 22:09:04,632 : INFO : EPOCH 4 - PROGRESS: at 80.54% examples, 309745 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:09:05,643 : INFO : EPOCH 4 - PROGRESS: at 82.67% examples, 309861 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:09:06,660 : INFO : EPOCH 4 - PROGRESS: at 84.69% examples, 310234 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:09:07,666 : INFO : EPOCH 4 - PROGRESS: at 86.18% examples, 310681 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:09:08,671 : INFO : EPOCH 4 - PROGRESS: at 87.81% examples, 311102 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:09:09,674 : INFO : EPOCH 4 - PROGRESS: at 89.35% examples, 311671 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:09:10,694 : INFO : EPOCH 4 - PROGRESS: at 90.85% examples, 311910 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:09:11,736 : INFO : EPOCH 4 - PROGRESS: at 92.31% examples, 312225 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:09:12,743 : INFO : EPOCH 4 - PROGRESS: at 93.57% examples, 312732 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:09:13,753 : INFO : EPOCH 4 - PROGRESS: at 94.81% examples, 313194 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:09:14,756 : INFO : EPOCH 4 - PROGRESS: at 95.97% examples, 313466 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:09:15,767 : INFO : EPOCH 4 - PROGRESS: at 97.27% examples, 313816 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:09:16,779 : INFO : EPOCH 4 - PROGRESS: at 98.51% examples, 314351 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:09:17,781 : INFO : EPOCH 4 - PROGRESS: at 99.75% examples, 314817 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:09:17,919 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-02-26 22:09:17,949 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-02-26 22:09:17,969 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-02-26 22:09:17,983 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-02-26 22:09:17,985 : INFO : EPOCH - 4 : training on 27374377 raw words (21281976 effective words) took 67.6s, 314871 effective words/s\n",
      "2021-02-26 22:09:19,047 : INFO : EPOCH 5 - PROGRESS: at 2.38% examples, 325480 words/s, in_qsize 7, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-26 22:09:20,052 : INFO : EPOCH 5 - PROGRESS: at 4.47% examples, 340064 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:09:21,067 : INFO : EPOCH 5 - PROGRESS: at 6.67% examples, 339634 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:09:22,099 : INFO : EPOCH 5 - PROGRESS: at 8.61% examples, 339490 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:09:23,124 : INFO : EPOCH 5 - PROGRESS: at 10.23% examples, 340052 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:09:24,134 : INFO : EPOCH 5 - PROGRESS: at 12.02% examples, 340838 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:09:25,137 : INFO : EPOCH 5 - PROGRESS: at 13.51% examples, 341138 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:09:26,192 : INFO : EPOCH 5 - PROGRESS: at 15.39% examples, 340185 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:09:27,249 : INFO : EPOCH 5 - PROGRESS: at 17.11% examples, 340880 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:09:28,271 : INFO : EPOCH 5 - PROGRESS: at 19.06% examples, 342930 words/s, in_qsize 8, out_qsize 0\n",
      "2021-02-26 22:09:29,284 : INFO : EPOCH 5 - PROGRESS: at 20.89% examples, 343271 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:09:30,325 : INFO : EPOCH 5 - PROGRESS: at 22.74% examples, 342963 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:09:31,368 : INFO : EPOCH 5 - PROGRESS: at 24.93% examples, 343806 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:09:32,379 : INFO : EPOCH 5 - PROGRESS: at 26.92% examples, 344549 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:09:33,413 : INFO : EPOCH 5 - PROGRESS: at 28.82% examples, 343890 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:09:34,415 : INFO : EPOCH 5 - PROGRESS: at 30.58% examples, 344398 words/s, in_qsize 6, out_qsize 1\n",
      "2021-02-26 22:09:35,417 : INFO : EPOCH 5 - PROGRESS: at 31.94% examples, 344381 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:09:36,427 : INFO : EPOCH 5 - PROGRESS: at 33.27% examples, 344216 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:09:37,472 : INFO : EPOCH 5 - PROGRESS: at 34.73% examples, 343959 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:09:38,500 : INFO : EPOCH 5 - PROGRESS: at 36.10% examples, 344678 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:09:39,510 : INFO : EPOCH 5 - PROGRESS: at 37.46% examples, 344161 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:09:40,520 : INFO : EPOCH 5 - PROGRESS: at 38.89% examples, 344809 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:09:41,522 : INFO : EPOCH 5 - PROGRESS: at 40.13% examples, 344503 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:09:42,533 : INFO : EPOCH 5 - PROGRESS: at 41.41% examples, 344099 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:09:43,544 : INFO : EPOCH 5 - PROGRESS: at 42.68% examples, 344042 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:09:44,546 : INFO : EPOCH 5 - PROGRESS: at 44.00% examples, 343784 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:09:45,548 : INFO : EPOCH 5 - PROGRESS: at 45.29% examples, 343795 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:09:46,556 : INFO : EPOCH 5 - PROGRESS: at 46.61% examples, 343939 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:09:47,576 : INFO : EPOCH 5 - PROGRESS: at 48.12% examples, 343962 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:09:48,585 : INFO : EPOCH 5 - PROGRESS: at 49.64% examples, 343652 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:09:49,611 : INFO : EPOCH 5 - PROGRESS: at 51.26% examples, 344209 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:09:50,626 : INFO : EPOCH 5 - PROGRESS: at 52.85% examples, 343139 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:09:51,640 : INFO : EPOCH 5 - PROGRESS: at 54.61% examples, 341865 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:09:52,640 : INFO : EPOCH 5 - PROGRESS: at 56.87% examples, 341899 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:09:53,642 : INFO : EPOCH 5 - PROGRESS: at 58.62% examples, 340195 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:09:54,659 : INFO : EPOCH 5 - PROGRESS: at 60.78% examples, 338687 words/s, in_qsize 6, out_qsize 1\n",
      "2021-02-26 22:09:55,671 : INFO : EPOCH 5 - PROGRESS: at 62.34% examples, 337722 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:09:56,684 : INFO : EPOCH 5 - PROGRESS: at 63.78% examples, 337615 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:09:57,728 : INFO : EPOCH 5 - PROGRESS: at 64.99% examples, 336645 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:09:58,728 : INFO : EPOCH 5 - PROGRESS: at 66.61% examples, 337017 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:09:59,729 : INFO : EPOCH 5 - PROGRESS: at 68.09% examples, 336870 words/s, in_qsize 6, out_qsize 1\n",
      "2021-02-26 22:10:00,783 : INFO : EPOCH 5 - PROGRESS: at 69.25% examples, 335586 words/s, in_qsize 8, out_qsize 0\n",
      "2021-02-26 22:10:01,788 : INFO : EPOCH 5 - PROGRESS: at 70.24% examples, 333689 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:10:02,833 : INFO : EPOCH 5 - PROGRESS: at 71.50% examples, 332613 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:10:03,899 : INFO : EPOCH 5 - PROGRESS: at 72.80% examples, 331570 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:10:04,914 : INFO : EPOCH 5 - PROGRESS: at 74.02% examples, 330953 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:10:05,951 : INFO : EPOCH 5 - PROGRESS: at 75.38% examples, 330828 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:10:07,002 : INFO : EPOCH 5 - PROGRESS: at 76.89% examples, 330659 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:10:08,002 : INFO : EPOCH 5 - PROGRESS: at 78.93% examples, 330871 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:10:09,031 : INFO : EPOCH 5 - PROGRESS: at 81.21% examples, 331225 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:10:10,048 : INFO : EPOCH 5 - PROGRESS: at 83.32% examples, 330473 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:10:11,094 : INFO : EPOCH 5 - PROGRESS: at 85.01% examples, 330004 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:10:12,175 : INFO : EPOCH 5 - PROGRESS: at 86.63% examples, 329669 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:10:13,215 : INFO : EPOCH 5 - PROGRESS: at 88.14% examples, 329555 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:10:14,217 : INFO : EPOCH 5 - PROGRESS: at 89.62% examples, 329696 words/s, in_qsize 8, out_qsize 0\n",
      "2021-02-26 22:10:15,227 : INFO : EPOCH 5 - PROGRESS: at 91.15% examples, 329805 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:10:16,236 : INFO : EPOCH 5 - PROGRESS: at 92.42% examples, 329356 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:10:17,244 : INFO : EPOCH 5 - PROGRESS: at 93.44% examples, 328416 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:10:18,253 : INFO : EPOCH 5 - PROGRESS: at 94.53% examples, 327893 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:10:19,297 : INFO : EPOCH 5 - PROGRESS: at 95.54% examples, 326964 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:10:20,312 : INFO : EPOCH 5 - PROGRESS: at 96.89% examples, 327569 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:10:21,368 : INFO : EPOCH 5 - PROGRESS: at 97.96% examples, 326611 words/s, in_qsize 6, out_qsize 1\n",
      "2021-02-26 22:10:22,394 : INFO : EPOCH 5 - PROGRESS: at 99.12% examples, 326652 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-26 22:10:23,096 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-02-26 22:10:23,110 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-02-26 22:10:23,117 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-02-26 22:10:23,163 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-02-26 22:10:23,164 : INFO : EPOCH - 5 : training on 27374377 raw words (21283266 effective words) took 65.2s, 326555 effective words/s\n",
      "2021-02-26 22:10:23,165 : INFO : training on a 136871885 raw words (106412714 effective words) took 343.9s, 309391 effective words/s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(106412714, 136871885)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors9.train(tokenized_text1, total_examples=vectors9.corpus_count, epochs=vectors9.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_word9= [list(vectors6.wv.vocab.keys())[(i+1)*1000] for i in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Conceptual', 'fluent', 'seventh', 'manage', 'publicity']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed_word9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "257022"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(vectors9.wv.vocab.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-26 22:11:50,646 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar to: neuroscience\n",
      "[('neurobiology', 0.9721717834472656), ('psychology', 0.971102774143219), ('interdisciplinarity', 0.9698944091796875), ('imaginative', 0.9662922620773315), ('cultivating', 0.9651345014572144), ('neurosciences', 0.9640445709228516), ('metacognition', 0.958501935005188), ('collegiality', 0.9539251327514648), ('psychobiology', 0.9532018899917603), ('biopsychology', 0.9521270990371704)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Inspect words with vectors most similar to a given word\n",
    "print(\"Most similar to:\", 'neuroscience')\n",
    "print(vectors9.wv.most_similar('neuroscience'))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar to: neuroscience\n",
      "[('biology', 0.9733627438545227), ('furthering', 0.9680370688438416), ('neurobiology', 0.9664344787597656), ('epidemiology', 0.9656774997711182), ('psychology', 0.9603279829025269), ('informatics', 0.9592504501342773), ('genomics', 0.9549347162246704), ('relevance', 0.9538663029670715), ('discovery', 0.9513333439826965), ('STS', 0.9497036933898926)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Inspect words with vectors most similar to a given word\n",
    "print(\"Most similar to:\", 'neuroscience')\n",
    "print(vectors4.wv.most_similar('neuroscience'))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['half', 'whether', 'neuroscience', 'Lonza', 'tightly']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed_word4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63538"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(vectors4.wv.vocab.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-26 21:50:18,179 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar to: neuroscience\n",
      "[('furthering', 0.9842066764831543), ('informational', 0.9749946594238281), ('relevance', 0.9741153717041016), ('neurobiology', 0.96800696849823), ('interest', 0.9663718342781067), ('informatics', 0.9641363620758057), ('technological', 0.9639126062393188), ('advancing', 0.9617303609848022), ('playing', 0.9597301483154297), ('sciences', 0.9593894481658936)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Inspect words with vectors most similar to a given word\n",
    "print(\"Most similar to:\", 'neuroscience')\n",
    "print(vectors4.wv.most_similar('neuroscience'))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
